[
    {
      "model": "gpt-4o-mini",
      "test_id": "6.json",
      "difficulty": "easy",
      "tags": [
        "METADATA_EXTRACTION",
        "MEDIA_EXTRACTION"
      ],
      "score": 1.0,
      "cost": 0.000192225,
      "usage": {
        "input_tokens": 9495,
        "output_tokens": 83,
        "total_tokens": 9578
      },
      "latency": 1.9272420406341553,
      "test_case": {
        "input": {
          "input_file": "simpleanalytics.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract favicon URLs from the provided webpage HTML.",
        "user_prompt": "Please extract all favicon URLs from the HTML head section. Include any favicon references with different sizes. Format the output as a JSON array of objects with size and URL properties.\n\nFormat the output as:\n{\n \"favicons\": [{\n   \"size\": string,\n   \"url\": string\n }]\n}",
        "expected_output": {
          "favicons": [
            {
              "size": "180x180",
              "url": "/apple-touch-icon.png"
            },
            {
              "size": "32x32",
              "url": "/favicon-32x32.png"
            },
            {
              "size": "16x16",
              "url": "/favicon-16x16.png"
            }
          ]
        },
        "tags": [
          "METADATA_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "difficulty": "easy",
        "test_id": "6.json"
      },
      "model_output": {
        "favicons": [
          {
            "size": "180x180",
            "url": "/apple-touch-icon.png"
          },
          {
            "size": "32x32",
            "url": "/favicon-32x32.png"
          },
          {
            "size": "16x16",
            "url": "/favicon-16x16.png"
          }
        ]
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "7.json",
      "difficulty": "easy",
      "tags": [
        "STRUCTURAL_EXTRACTION",
        "METADATA_EXTRACTION",
        "ANALYTICS_EXTRACTION"
      ],
      "score": 1.0000000715255737,
      "cost": 1.9905e-05,
      "usage": {
        "input_tokens": 207,
        "output_tokens": 28,
        "total_tokens": 235
      },
      "latency": 2.0999789237976074,
      "test_case": {
        "expected_output": {
          "title": "Example Domain",
          "num_links": 1,
          "num_paragraphs": 2
        },
        "input": {
          "input_file": "example.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
        "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON: Expected output schema:\n{\n  \"title\": \"string\",\n  \"num_links\": \"number\",\n  \"num_paragraphs\": \"number\"\n}",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "difficulty": "easy",
        "test_id": "7.json"
      },
      "model_output": {
        "title": "Example Domain",
        "num_links": 1,
        "num_paragraphs": 2
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "1.json",
      "difficulty": "easy",
      "tags": [
        "ANALYTICS_EXTRACTION"
      ],
      "score": 0.9999999642372132,
      "cost": 0.0005615999999999999,
      "usage": {
        "input_tokens": 36320,
        "output_tokens": 28,
        "total_tokens": 36348
      },
      "latency": 2.376969814300537,
      "test_case": {
        "expected_output": {
          "insights": {
            "total_pageviews": 584,
            "total_visitors": 417
          }
        },
        "input": {
          "input_file": "analytics.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
        "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON:\n- Total pageviews\n- Total visitors\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"total_pageviews\": number,\n    \"total_visitors\": number\n  }\n}",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "difficulty": "easy",
        "test_id": "1.json"
      },
      "model_output": {
        "insights": {
          "total_pageviews": 584,
          "total_visitors": 417
        }
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "2.json",
      "difficulty": "easy",
      "tags": [
        "ANALYTICS_EXTRACTION"
      ],
      "score": 1.0,
      "cost": 0.0005726700000000001,
      "usage": {
        "input_tokens": 36338,
        "output_tokens": 46,
        "total_tokens": 36384
      },
      "latency": 2.5265610218048096,
      "test_case": {
        "expected_output": {
          "insights": {
            "referral_sources": {
              "direct": 240,
              "twitter.com": 68,
              "news.ycombinator.com": 41
            }
          }
        },
        "input": {
          "input_file": "analytics.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract the top 3 referral sources from the provided webpage HTML.",
        "user_prompt": "Please analyze the webpage HTML content and extract the top 3 referral sources with their pageview counts into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"referral_sources\": {\n      \"direct\": number,\n      \"twitter.com\": number,\n      \"news.ycombinator.com\": number\n    }\n  }\n}",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "difficulty": "easy",
        "test_id": "2.json"
      },
      "model_output": {
        "insights": {
          "referral_sources": {
            "direct": 240,
            "twitter.com": 68,
            "news.ycombinator.com": 41
          }
        }
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "3.json",
      "difficulty": "easy",
      "tags": [
        "ANALYTICS_EXTRACTION"
      ],
      "score": 0.9999999284744263,
      "cost": 0.0005694599999999999,
      "usage": {
        "input_tokens": 36324,
        "output_tokens": 41,
        "total_tokens": 36365
      },
      "latency": 1.835641860961914,
      "test_case": {
        "expected_output": {
          "insights": {
            "device_usage": {
              "mobile": 68,
              "desktop": 32,
              "tablet": 0.7
            }
          }
        },
        "input": {
          "input_file": "analytics.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract device usage percentages from the provided webpage HTML.",
        "user_prompt": "Please analyze the webpage HTML content and extract the percentage breakdown of device types used into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"device_usage\": {\n      \"mobile\": number,\n      \"desktop\": number,\n      \"tablet\": number\n    }\n  }\n}",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "difficulty": "easy",
        "test_id": "3.json"
      },
      "model_output": {
        "insights": {
          "device_usage": {
            "mobile": 68,
            "desktop": 32,
            "tablet": 0.7
          }
        }
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "4.json",
      "difficulty": "easy",
      "tags": [
        "STRUCTURAL_EXTRACTION",
        "METADATA_EXTRACTION",
        "ANALYTICS_EXTRACTION"
      ],
      "score": 0.9764013528823853,
      "cost": 0.0013226849999999999,
      "usage": {
        "input_tokens": 86419,
        "output_tokens": 44,
        "total_tokens": 86463
      },
      "latency": 4.695230007171631,
      "test_case": {
        "input": {
          "input_file": "reddit.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract basic post information from the provided Reddit webpage HTML.",
        "user_prompt": "Please analyze the Reddit webpage HTML content and extract the following basic post information into a JSON object:\n- Post title\n- Author name\n- Subreddit name\n- Post score\n\nFormat the output as:\n{\n \"post_title\": string,\n \"author\": string,\n \"subreddit\": string,\n \"post_score\": string\n}",
        "expected_output": {
          "post_title": "Is there a simple way to monitor Bedrock Costs?",
          "author": "Bob321423",
          "subreddit": "r/aws",
          "post_score": "5"
        },
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "difficulty": "easy",
        "test_id": "4.json"
      },
      "model_output": {
        "post_title": "Is there a simple way to monitor Bedrock Costs?",
        "author": "Bob321423",
        "subreddit": "aws",
        "post_score": "5"
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "5.json",
      "difficulty": "easy",
      "tags": [
        "STRUCTURAL_EXTRACTION",
        "METADATA_EXTRACTION",
        "ANALYTICS_EXTRACTION"
      ],
      "score": 0.9618167161941529,
      "cost": 0.0013252350000000001,
      "usage": {
        "input_tokens": 86429,
        "output_tokens": 48,
        "total_tokens": 86477
      },
      "latency": 9.345737934112549,
      "test_case": {
        "input": {
          "input_file": "reddit.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
        "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": number,\n \"active_members\": number,\n \"created_date\": string,\n \"community_type\": string\n}",
        "expected_output": {
          "community_name": "r/aws",
          "total_members": 316355,
          "active_members": 48,
          "created_date": "Jan 26, 2008",
          "community_type": "Public"
        },
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "difficulty": "easy",
        "test_id": "5.json"
      },
      "model_output": {
        "community_name": "aws",
        "total_members": 316355,
        "active_members": 48,
        "created_date": "2008-01-26",
        "community_type": "public"
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "1.json",
      "difficulty": "medium",
      "tags": [
        "ANALYTICS_EXTRACTION",
        "SEMANTIC_EXTRACTION"
      ],
      "score": 0.7967832565307618,
      "cost": 0.00057867,
      "usage": {
        "input_tokens": 36378,
        "output_tokens": 55,
        "total_tokens": 36433
      },
      "latency": 2.7394721508026123,
      "test_case": {
        "expected_output": {
          "insights": {
            "top_page": {
              "url": "/blog/tone-evaluation",
              "pageviews": 296,
              "percentage_of_total": 50.5,
              "has_social_traffic": true
            }
          }
        },
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "input": {
          "input_file": "analytics.html"
        },
        "system_prompt": "You are a data extraction assistant. Analyze the most popular page's metrics from the provided webpage HTML.",
        "user_prompt": "Please analyze the webpage HTML content and extract information about the most visited page into JSON:\n- The page URL\n- Number of pageviews\n- Calculate what percentage of total pageviews this represents\n- Whether it received any social media traffic (from Twitter, Facebook, or LinkedIn)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"top_page\": {\n      \"url\": string,\n      \"pageviews\": number,\n      \"percentage_of_total\": number,\n      \"has_social_traffic\": boolean\n    }\n  }\n}",
        "difficulty": "medium",
        "test_id": "1.json"
      },
      "model_output": {
        "insights": {
          "top_page": {
            "url": "/peytoncasper.com",
            "pageviews": 584,
            "percentage_of_total": 100,
            "has_social_traffic": true
          }
        }
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "2.json",
      "difficulty": "medium",
      "tags": [
        "ANALYTICS_EXTRACTION"
      ],
      "score": 0.9776516556739807,
      "cost": 0.0005808149999999999,
      "usage": {
        "input_tokens": 36361,
        "output_tokens": 59,
        "total_tokens": 36420
      },
      "latency": 3.4892451763153076,
      "test_case": {
        "expected_output": {
          "insights": {
            "mobile_stats": {
              "percentage": 68,
              "dominant_browser": "iOS Safari",
              "browser_share": 48,
              "alignment_score": 0.71
            }
          }
        },
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "input": {
          "input_file": "analytics.html"
        },
        "system_prompt": "You are a data extraction assistant. Analyze mobile usage patterns from the provided webpage HTML.",
        "user_prompt": "Please analyze the webpage HTML content and extract mobile usage patterns into JSON:\n- Mobile device usage percentage\n- Most used mobile browser\n- That browser's overall share percentage\n- Calculate an alignment score (browser_share/mobile_percentage)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"mobile_stats\": {\n      \"percentage\": number,\n      \"dominant_browser\": string,\n      \"browser_share\": number,\n      \"alignment_score\": number\n    }\n  }\n}",
        "difficulty": "medium",
        "test_id": "2.json"
      },
      "model_output": {
        "insights": {
          "mobile_stats": {
            "percentage": 68,
            "dominant_browser": "iOS Safari",
            "browser_share": 48,
            "alignment_score": 0.7058823529411765
          }
        }
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "3.json",
      "difficulty": "medium",
      "tags": [
        "ANALYTICS_EXTRACTION",
        "SEMANTIC_EXTRACTION"
      ],
      "score": 0.9311822414398193,
      "cost": 0.00135276,
      "usage": {
        "input_tokens": 86424,
        "output_tokens": 94,
        "total_tokens": 86518
      },
      "latency": 10.617358922958374,
      "test_case": {
        "input": {
          "input_file": "reddit.html"
        },
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "system_prompt": "You are a data extraction assistant. Analyze comment patterns and extract comment-related metrics from the provided Reddit webpage HTML.",
        "user_prompt": "Please analyze the Reddit webpage HTML and extract the following comment information into JSON:\n- Total number of comments\n- List of all comment authors\n- Timeline of comments (how long ago each was posted)\n\nFormat the output as:\n{\n \"total_comments\": number,\n \"comment_authors\": string[],\n \"comments_timeline\": string[]\n}",
        "expected_output": {
          "total_comments": 5,
          "comment_authors": [
            "Truelikegiroux",
            "TechMktr",
            "MrPebblesMeow",
            "AdRepulsive7837",
            "noydoc"
          ],
          "comments_timeline": [
            "5 months ago",
            "5 months ago",
            "4 months ago",
            "4 months ago",
            "2 months ago"
          ]
        },
        "difficulty": "medium",
        "test_id": "3.json"
      },
      "model_output": {
        "total_comments": 5,
        "comment_authors": [
          "Truelikegiroux",
          "TechMktr",
          "MrPebblesMeow",
          "AdRepulsive7837",
          "noydoc"
        ],
        "comments_timeline": [
          "5mo ago",
          "5mo ago",
          "4mo ago",
          "4mo ago",
          "2mo ago"
        ]
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "4.json",
      "difficulty": "medium",
      "tags": [
        "METADATA_EXTRACTION",
        "ANALYTICS_EXTRACTION"
      ],
      "score": 0.9773620128631592,
      "cost": 0.001325835,
      "usage": {
        "input_tokens": 86429,
        "output_tokens": 49,
        "total_tokens": 86478
      },
      "latency": 8.541434049606323,
      "test_case": {
        "input": {
          "input_file": "reddit.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
        "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": string,\n \"active_members\": string,\n \"created_date\": string,\n \"community_type\": string\n}",
        "expected_output": {
          "community_name": "aws",
          "total_members": "316355",
          "active_members": "48",
          "created_date": "Jan 26, 2008",
          "community_type": "Public"
        },
        "tags": [
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "difficulty": "medium",
        "test_id": "4.json"
      },
      "model_output": {
        "community_name": "aws",
        "total_members": "316K",
        "active_members": "48",
        "created_date": "January 26, 2008",
        "community_type": "Public"
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "5.json",
      "difficulty": "medium",
      "tags": [
        "STRUCTURAL_EXTRACTION",
        "MEDIA_EXTRACTION"
      ],
      "score": 1.0,
      "cost": 0.00020814,
      "usage": {
        "input_tokens": 9516,
        "output_tokens": 109,
        "total_tokens": 9625
      },
      "latency": 1.7423758506774902,
      "test_case": {
        "input": {
          "input_file": "simpleanalytics.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract the main logo SVG content and properties from the provided webpage HTML.",
        "user_prompt": "Please extract the main navigation logo SVG element, including its viewBox, dimensions, and path data. Don't deconstruct the paths. Store them as strings wtih the tag inside. \n\nFormat the output as JSON:\n{\n \"logo\": {\n   \"viewBox\": string,\n   \"width\": string,\n   \"height\": string,\n   \"paths\": string[]\n }\n}",
        "expected_output": {
          "logo": {
            "viewBox": "0 0 100 100",
            "width": "30px",
            "height": "30px",
            "paths": [
              "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
              "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
              "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
            ]
          }
        },
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "difficulty": "medium",
        "test_id": "5.json"
      },
      "model_output": {
        "logo": {
          "viewBox": "0 0 100 100",
          "width": "30px",
          "height": "30px",
          "paths": [
            "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
            "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
            "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
          ]
        }
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "1.json",
      "difficulty": "hard",
      "tags": [
        "ANALYTICS_EXTRACTION",
        "METADATA_EXTRACTION",
        "STRUCTURAL_EXTRACTION"
      ],
      "score": 0.9323653101921081,
      "cost": 0.0005888549999999999,
      "usage": {
        "input_tokens": 36377,
        "output_tokens": 72,
        "total_tokens": 36449
      },
      "latency": 2.020555019378662,
      "test_case": {
        "expected_output": {
          "insights": {
            "most_popular_page": "/blog/tone-evaluation",
            "most_popular_referral_source": "twitter.com",
            "dominant_device_type": "Mobile",
            "dominant_browser": "iOS Safari",
            "dominant_country": "United States"
          }
        },
        "input": {
          "input_file": "analytics.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract key analytics insights from the provided webpage HTML and format them according to the specified schema.",
        "user_prompt": "Please analyze the webpage HTML content and extract the following analytics insights into a JSON object:\n- Most visited page\n- Top referral source\n- Most common device type\n- Most used browser\n- Country with highest traffic\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"most_popular_page\": string,\n    \"most_popular_referral_source\": string,\n    \"dominant_device_type\": string,\n    \"dominant_browser\": string,\n    \"dominant_country\": string\n  }\n}",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "METADATA_EXTRACTION",
          "STRUCTURAL_EXTRACTION"
        ],
        "difficulty": "hard",
        "test_id": "1.json"
      },
      "model_output": {
        "insights": {
          "most_popular_page": "/peytoncasper.com/blog/tone-evaluation",
          "most_popular_referral_source": "direct",
          "dominant_device_type": "Mobile",
          "dominant_browser": "iOS Safari",
          "dominant_country": "United States"
        }
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "2.json",
      "difficulty": "hard",
      "tags": [
        "STRUCTURAL_EXTRACTION",
        "METADATA_EXTRACTION"
      ],
      "score": 0.9629714965820313,
      "cost": 0.0015080699999999998,
      "usage": {
        "input_tokens": 86458,
        "output_tokens": 352,
        "total_tokens": 86810
      },
      "latency": 11.789073944091797,
      "test_case": {
        "input": {
          "input_file": "reddit.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract and organize the complete navigation structure and resource links from the provided Reddit webpage HTML.",
        "user_prompt": "Please analyze the Reddit webpage HTML and extract the following navigation structure into JSON:\n- Main resource links with their titles and URLs\n- Policy links with their titles and URLs\n- All sidebar resource links\n\nOrganize the information hierarchically and format the output as:\n{\n \"resources\": {\n   \"main_links\": [{ \"title\": string, \"url\": string }],\n   \"policies\": [{ \"title\": string, \"url\": string }],\n   \"sidebar_resources\": string[]\n }\n}",
        "expected_output": {
          "resources": {
            "main_links": [
              {
                "title": "About Reddit",
                "url": "https://www.redditinc.com"
              },
              {
                "title": "Advertise",
                "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
              },
              {
                "title": "Help",
                "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
              },
              {
                "title": "Blog",
                "url": "https://redditblog.com/"
              },
              {
                "title": "Careers",
                "url": "https://www.redditinc.com/careers"
              },
              {
                "title": "Press",
                "url": "https://www.redditinc.com/press"
              }
            ],
            "policies": [
              {
                "title": "Content Policy",
                "url": "https://www.redditinc.com/policies/content-policy"
              },
              {
                "title": "Privacy Policy",
                "url": "https://www.reddit.com/policies/privacy-policy"
              },
              {
                "title": "User Agreement",
                "url": "https://www.redditinc.com/policies/user-agreement"
              }
            ],
            "sidebar_resources": [
              "Amazon Web Services blog",
              "AWS status page",
              "AWS documentation",
              "AWS YouTube channel",
              "AWS Samples on GitHub",
              "AWS Labs on GitHub",
              "AWS General Reference",
              "High Scalability",
              "re:Invent Videos",
              "Workshops",
              "AWS Geek: Cloud Diagrams",
              "AWS Stash",
              "AWS Architecture Center",
              "AWS re:Post"
            ]
          }
        },
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION"
        ],
        "difficulty": "hard",
        "test_id": "2.json"
      },
      "model_output": {
        "resources": {
          "main_links": [
            {
              "title": "Home",
              "url": "/"
            },
            {
              "title": "r/aws",
              "url": "/r/aws/"
            },
            {
              "title": "Create Post",
              "url": "/r/aws/submit"
            },
            {
              "title": "Advertise on Reddit",
              "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=nav_cta"
            },
            {
              "title": "Open chat",
              "url": "#"
            },
            {
              "title": "Open inbox",
              "url": "#"
            }
          ],
          "policies": [
            {
              "title": "Content Policy",
              "url": "https://www.redditinc.com/policies/content-policy"
            },
            {
              "title": "Privacy Policy",
              "url": "https://www.reddit.com/policies/privacy-policy"
            },
            {
              "title": "User Agreement",
              "url": "https://www.redditinc.com/policies/user-agreement"
            }
          ],
          "sidebar_resources": [
            "Amazon Web Services blog",
            "AWS status page",
            "AWS documentation",
            "AWS YouTube channel",
            "AWS Samples on GitHub",
            "AWS Labs on GitHub",
            "AWS General Reference",
            "High Scalability",
            "re:Invent Videos",
            "Workshops",
            "AWS Geek: Cloud Diagrams",
            "AWS Stash",
            "AWS Architecture Center",
            "AWS re:Post"
          ]
        }
      }
    },
    {
      "model": "gpt-4o-mini",
      "test_id": "3.json",
      "difficulty": "hard",
      "tags": [
        "MEDIA_EXTRACTION"
      ],
      "score": 1.0,
      "cost": 0.000146985,
      "usage": {
        "input_tokens": 9479,
        "output_tokens": 8,
        "total_tokens": 9487
      },
      "latency": 0.8888428211212158,
      "test_case": {
        "input": {
          "input_file": "simpleanalytics.html"
        },
        "system_prompt": "You are a data extraction assistant. Extract and decode any base64 encoded logo images from the provided webpage HTML.",
        "user_prompt": "Please analyze the HTML for any base64 encoded logo images. Extract the base64 encoded string or return empty string \n\nFormat the output as JSON:\n{\n \"encodedImage\": string\n}",
        "expected_output": {
          "encodedImage": ""
        },
        "tags": [
          "MEDIA_EXTRACTION"
        ],
        "difficulty": "hard",
        "test_id": "3.json"
      },
      "model_output": {
        "encodedImage": ""
      }
    },
    {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "6.json",
        "difficulty": "easy",
        "tags": [
          "METADATA_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.00044089500000000007,
        "usage": {
          "input_tokens": 12081,
          "output_tokens": 129,
          "total_tokens": 12210
        },
        "latency": 2.072942018508911,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract favicon URLs from the provided webpage HTML.",
          "user_prompt": "Please extract all favicon URLs from the HTML head section. Include any favicon references with different sizes. Format the output as a JSON array of objects with size and URL properties.\n\nFormat the output as:\n{\n \"favicons\": [{\n   \"size\": string,\n   \"url\": string\n }]\n}",
          "expected_output": {
            "favicons": [
              {
                "size": "180x180",
                "url": "/apple-touch-icon.png"
              },
              {
                "size": "32x32",
                "url": "/favicon-32x32.png"
              },
              {
                "size": "16x16",
                "url": "/favicon-16x16.png"
              }
            ]
          },
          "tags": [
            "METADATA_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "6.json"
        },
        "model_output": {
          "favicons": [
            {
              "size": "180x180",
              "url": "/apple-touch-icon.png"
            },
            {
              "size": "32x32",
              "url": "/favicon-32x32.png"
            },
            {
              "size": "16x16",
              "url": "/favicon-16x16.png"
            }
          ]
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "7.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0000000715255737,
        "cost": 2.212e-05,
        "usage": {
          "input_tokens": 216,
          "output_tokens": 104,
          "total_tokens": 320
        },
        "latency": 0.915809154510498,
        "test_case": {
          "expected_output": {
            "title": "Example Domain",
            "num_links": 1,
            "num_paragraphs": 2
          },
          "input": {
            "input_file": "example.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON: Expected output schema:\n{\n  \"title\": \"string\",\n  \"num_links\": \"number\",\n  \"num_paragraphs\": \"number\"\n}",
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "7.json"
        },
        "model_output": {
          "title": "Example Domain",
          "num_links": 1,
          "num_paragraphs": 2
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "1.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999642372132,
        "cost": 0.0016426550000000002,
        "usage": {
          "input_tokens": 46813,
          "output_tokens": 30,
          "total_tokens": 46843
        },
        "latency": 2.725278854370117,
        "test_case": {
          "expected_output": {
            "insights": {
              "total_pageviews": 584,
              "total_visitors": 417
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON:\n- Total pageviews\n- Total visitors\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"total_pageviews\": number,\n    \"total_visitors\": number\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "total_pageviews": 584,
            "total_visitors": 417
          }
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "2.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0016573550000000001,
        "usage": {
          "input_tokens": 46833,
          "output_tokens": 130,
          "total_tokens": 46963
        },
        "latency": 3.95450496673584,
        "test_case": {
          "expected_output": {
            "insights": {
              "referral_sources": {
                "direct": 240,
                "twitter.com": 68,
                "news.ycombinator.com": 41
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the top 3 referral sources from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the top 3 referral sources with their pageview counts into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"referral_sources\": {\n      \"direct\": number,\n      \"twitter.com\": number,\n      \"news.ycombinator.com\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "referral_sources": {
              "direct": 240,
              "twitter.com": 68,
              "news.ycombinator.com": 41
            }
          }
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "3.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999284744263,
        "cost": 0.00164885,
        "usage": {
          "input_tokens": 46818,
          "output_tokens": 73,
          "total_tokens": 46891
        },
        "latency": 3.226583957672119,
        "test_case": {
          "expected_output": {
            "insights": {
              "device_usage": {
                "mobile": 68,
                "desktop": 32,
                "tablet": 0.7
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract device usage percentages from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the percentage breakdown of device types used into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"device_usage\": {\n      \"mobile\": number,\n      \"desktop\": number,\n      \"tablet\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "3.json"
        },
        "model_output": {
          "insights": {
            "device_usage": {
              "mobile": 68,
              "desktop": 32,
              "tablet": 0.7
            }
          }
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "4.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0037755550000000003,
        "usage": {
          "input_tokens": 107469,
          "output_tokens": 101,
          "total_tokens": 107570
        },
        "latency": 7.338042974472046,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic post information from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML content and extract the following basic post information into a JSON object:\n- Post title\n- Author name\n- Subreddit name\n- Post score\n\nFormat the output as:\n{\n \"post_title\": string,\n \"author\": string,\n \"subreddit\": string,\n \"post_score\": string\n}",
          "expected_output": {
            "post_title": "Is there a simple way to monitor Bedrock Costs?",
            "author": "Bob321423",
            "subreddit": "r/aws",
            "post_score": "5"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "4.json"
        },
        "model_output": {
          "post_title": "Is there a simple way to monitor Bedrock Costs?",
          "author": "Bob321423",
          "subreddit": "r/aws",
          "post_score": "5"
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "5.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.994428300857544,
        "cost": 0.00378252,
        "usage": {
          "input_tokens": 107484,
          "output_tokens": 147,
          "total_tokens": 107631
        },
        "latency": 7.670950889587402,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": number,\n \"active_members\": number,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "r/aws",
            "total_members": 316355,
            "active_members": 48,
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "5.json"
        },
        "model_output": {
          "community_name": "r/aws",
          "total_members": 316355,
          "active_members": 48,
          "created_date": "January 26, 2008",
          "community_type": "public"
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "1.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.8723500967025757,
        "cost": 0.0016828000000000001,
        "usage": {
          "input_tokens": 46872,
          "output_tokens": 302,
          "total_tokens": 47174
        },
        "latency": 5.907689094543457,
        "test_case": {
          "expected_output": {
            "insights": {
              "top_page": {
                "url": "/blog/tone-evaluation",
                "pageviews": 296,
                "percentage_of_total": 50.5,
                "has_social_traffic": true
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze the most popular page's metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract information about the most visited page into JSON:\n- The page URL\n- Number of pageviews\n- Calculate what percentage of total pageviews this represents\n- Whether it received any social media traffic (from Twitter, Facebook, or LinkedIn)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"top_page\": {\n      \"url\": string,\n      \"pageviews\": number,\n      \"percentage_of_total\": number,\n      \"has_social_traffic\": boolean\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "top_page": {
              "url": "/peytoncasper.com",
              "pageviews": 296,
              "percentage_of_total": 50.86,
              "has_social_traffic": true
            }
          }
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "2.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.00167076,
        "usage": {
          "input_tokens": 46860,
          "output_tokens": 219,
          "total_tokens": 47079
        },
        "latency": 5.026112079620361,
        "test_case": {
          "expected_output": {
            "insights": {
              "mobile_stats": {
                "percentage": 68,
                "dominant_browser": "iOS Safari",
                "browser_share": 48,
                "alignment_score": 0.71
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze mobile usage patterns from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract mobile usage patterns into JSON:\n- Mobile device usage percentage\n- Most used mobile browser\n- That browser's overall share percentage\n- Calculate an alignment score (browser_share/mobile_percentage)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"mobile_stats\": {\n      \"percentage\": number,\n      \"dominant_browser\": string,\n      \"browser_share\": number,\n      \"alignment_score\": number\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "mobile_stats": {
              "percentage": 68,
              "dominant_browser": "iOS Safari",
              "browser_share": 48,
              "alignment_score": 0.71
            }
          }
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "3.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9990242838859558,
        "cost": 0.0038032400000000003,
        "usage": {
          "input_tokens": 107476,
          "output_tokens": 297,
          "total_tokens": 107773
        },
        "latency": 9.457773923873901,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "system_prompt": "You are a data extraction assistant. Analyze comment patterns and extract comment-related metrics from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following comment information into JSON:\n- Total number of comments\n- List of all comment authors\n- Timeline of comments (how long ago each was posted)\n\nFormat the output as:\n{\n \"total_comments\": number,\n \"comment_authors\": string[],\n \"comments_timeline\": string[]\n}",
          "expected_output": {
            "total_comments": 5,
            "comment_authors": [
              "Truelikegiroux",
              "TechMktr",
              "MrPebblesMeow",
              "AdRepulsive7837",
              "noydoc"
            ],
            "comments_timeline": [
              "5 months ago",
              "5 months ago",
              "4 months ago",
              "4 months ago",
              "2 months ago"
            ]
          },
          "difficulty": "medium",
          "test_id": "3.json"
        },
        "model_output": {
          "total_comments": 5,
          "comment_authors": [
            "Truelikegiroux",
            "TechMktr",
            "MrPebblesMeow",
            "AdRepulsive7837",
            "noydoc"
          ],
          "comments_timeline": [
            "5 months ago",
            "5 months ago",
            "4 months ago",
            "3 months ago",
            "2 months ago"
          ]
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "4.json",
        "difficulty": "medium",
        "tags": [
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.961482048034668,
        "cost": 0.0037863000000000003,
        "usage": {
          "input_tokens": 107484,
          "output_tokens": 174,
          "total_tokens": 107658
        },
        "latency": 7.926112174987793,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": string,\n \"active_members\": string,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "aws",
            "total_members": "316355",
            "active_members": "48",
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "4.json"
        },
        "model_output": {
          "community_name": "r/aws",
          "total_members": "316K",
          "active_members": "48",
          "created_date": "January 26, 2008",
          "community_type": "public"
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "5.json",
        "difficulty": "medium",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 0.9401014089584351,
        "cost": 0.00044639,
        "usage": {
          "input_tokens": 12102,
          "output_tokens": 163,
          "total_tokens": 12265
        },
        "latency": 2.1070680618286133,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the main logo SVG content and properties from the provided webpage HTML.",
          "user_prompt": "Please extract the main navigation logo SVG element, including its viewBox, dimensions, and path data. Don't deconstruct the paths. Store them as strings wtih the tag inside. \n\nFormat the output as JSON:\n{\n \"logo\": {\n   \"viewBox\": string,\n   \"width\": string,\n   \"height\": string,\n   \"paths\": string[]\n }\n}",
          "expected_output": {
            "logo": {
              "viewBox": "0 0 100 100",
              "width": "30px",
              "height": "30px",
              "paths": [
                "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
                "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
                "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "5.json"
        },
        "model_output": {
          "logo": {
            "viewBox": "0 0 100 100",
            "width": "30",
            "height": "30",
            "paths": [
              "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
              "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
              "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
            ]
          }
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "1.json",
        "difficulty": "hard",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "METADATA_EXTRACTION",
          "STRUCTURAL_EXTRACTION"
        ],
        "score": 0.9855190753936768,
        "cost": 0.001651195,
        "usage": {
          "input_tokens": 46873,
          "output_tokens": 76,
          "total_tokens": 46949
        },
        "latency": 3.2524290084838867,
        "test_case": {
          "expected_output": {
            "insights": {
              "most_popular_page": "/blog/tone-evaluation",
              "most_popular_referral_source": "twitter.com",
              "dominant_device_type": "Mobile",
              "dominant_browser": "iOS Safari",
              "dominant_country": "United States"
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract key analytics insights from the provided webpage HTML and format them according to the specified schema.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following analytics insights into a JSON object:\n- Most visited page\n- Top referral source\n- Most common device type\n- Most used browser\n- Country with highest traffic\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"most_popular_page\": string,\n    \"most_popular_referral_source\": string,\n    \"dominant_device_type\": string,\n    \"dominant_browser\": string,\n    \"dominant_country\": string\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION",
            "METADATA_EXTRACTION",
            "STRUCTURAL_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "most_popular_page": "/peytoncasper.com/blog/tone-evaluation",
            "most_popular_referral_source": "twitter.com",
            "dominant_device_type": "Mobile",
            "dominant_browser": "iOS Safari",
            "dominant_country": "United States"
          }
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "2.json",
        "difficulty": "hard",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION"
        ],
        "score": 0.9275775324214588,
        "cost": 0.003817100000000001,
        "usage": {
          "input_tokens": 107508,
          "output_tokens": 388,
          "total_tokens": 107896
        },
        "latency": 10.883938074111938,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and organize the complete navigation structure and resource links from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following navigation structure into JSON:\n- Main resource links with their titles and URLs\n- Policy links with their titles and URLs\n- All sidebar resource links\n\nOrganize the information hierarchically and format the output as:\n{\n \"resources\": {\n   \"main_links\": [{ \"title\": string, \"url\": string }],\n   \"policies\": [{ \"title\": string, \"url\": string }],\n   \"sidebar_resources\": string[]\n }\n}",
          "expected_output": {
            "resources": {
              "main_links": [
                {
                  "title": "About Reddit",
                  "url": "https://www.redditinc.com"
                },
                {
                  "title": "Advertise",
                  "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
                },
                {
                  "title": "Help",
                  "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
                },
                {
                  "title": "Blog",
                  "url": "https://redditblog.com/"
                },
                {
                  "title": "Careers",
                  "url": "https://www.redditinc.com/careers"
                },
                {
                  "title": "Press",
                  "url": "https://www.redditinc.com/press"
                }
              ],
              "policies": [
                {
                  "title": "Content Policy",
                  "url": "https://www.redditinc.com/policies/content-policy"
                },
                {
                  "title": "Privacy Policy",
                  "url": "https://www.reddit.com/policies/privacy-policy"
                },
                {
                  "title": "User Agreement",
                  "url": "https://www.redditinc.com/policies/user-agreement"
                }
              ],
              "sidebar_resources": [
                "Amazon Web Services blog",
                "AWS status page",
                "AWS documentation",
                "AWS YouTube channel",
                "AWS Samples on GitHub",
                "AWS Labs on GitHub",
                "AWS General Reference",
                "High Scalability",
                "re:Invent Videos",
                "Workshops",
                "AWS Geek: Cloud Diagrams",
                "AWS Stash",
                "AWS Architecture Center",
                "AWS re:Post"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "2.json"
        },
        "model_output": {
          "resources": {
            "main_links": [
              {
                "title": "Home",
                "url": "/"
              },
              {
                "title": "Advertise",
                "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=nav_cta"
              },
              {
                "title": "Create Post",
                "url": "/r/aws/submit"
              },
              {
                "title": "Notifications",
                "url": "/user/peytoncasper/inbox"
              },
              {
                "title": "Premium",
                "url": "/premium"
              }
            ],
            "policies": [
              {
                "title": "Content Policy",
                "url": "https://www.redditinc.com/policies/content-policy"
              },
              {
                "title": "Privacy Policy",
                "url": "https://www.reddit.com/policies/privacy-policy"
              },
              {
                "title": "User Agreement",
                "url": "https://www.redditinc.com/policies/user-agreement"
              }
            ],
            "sidebar_resources": [
              "Amazon Web Services blog",
              "AWS status page",
              "AWS documentation",
              "AWS on YouTube",
              "AWS Labs on GitHub",
              "AWS General Reference",
              "r/AWS Wiki",
              "r/AWS Communities",
              "r/AWS Moderators",
              "About Reddit",
              "Advertise",
              "Blog",
              "Careers",
              "Press",
              "Best of Reddit Communities",
              "Topics",
              "Help"
            ]
          }
        }
      },
      {
        "model": "amazon.nova-micro-v1:0",
        "test_id": "3.json",
        "difficulty": "hard",
        "tags": [
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.000430675,
        "usage": {
          "input_tokens": 12065,
          "output_tokens": 60,
          "total_tokens": 12125
        },
        "latency": 1.1140110492706299,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and decode any base64 encoded logo images from the provided webpage HTML.",
          "user_prompt": "Please analyze the HTML for any base64 encoded logo images. Extract the base64 encoded string or return empty string \n\nFormat the output as JSON:\n{\n \"encodedImage\": string\n}",
          "expected_output": {
            "encodedImage": ""
          },
          "tags": [
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "3.json"
        },
        "model_output": {
          "encodedImage": ""
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "6.json",
        "difficulty": "easy",
        "tags": [
          "METADATA_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0007469399999999999,
        "usage": {
          "input_tokens": 12081,
          "output_tokens": 92,
          "total_tokens": 12173
        },
        "latency": 1.9908020496368408,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract favicon URLs from the provided webpage HTML.",
          "user_prompt": "Please extract all favicon URLs from the HTML head section. Include any favicon references with different sizes. Format the output as a JSON array of objects with size and URL properties.\n\nFormat the output as:\n{\n \"favicons\": [{\n   \"size\": string,\n   \"url\": string\n }]\n}",
          "expected_output": {
            "favicons": [
              {
                "size": "180x180",
                "url": "/apple-touch-icon.png"
              },
              {
                "size": "32x32",
                "url": "/favicon-32x32.png"
              },
              {
                "size": "16x16",
                "url": "/favicon-16x16.png"
              }
            ]
          },
          "tags": [
            "METADATA_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "6.json"
        },
        "model_output": {
          "favicons": [
            {
              "size": "180x180",
              "url": "/apple-touch-icon.png"
            },
            {
              "size": "32x32",
              "url": "/favicon-32x32.png"
            },
            {
              "size": "16x16",
              "url": "/favicon-16x16.png"
            }
          ]
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "7.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0000000715255737,
        "cost": 3.6719999999999994e-05,
        "usage": {
          "input_tokens": 216,
          "output_tokens": 99,
          "total_tokens": 315
        },
        "latency": 1.1535649299621582,
        "test_case": {
          "expected_output": {
            "title": "Example Domain",
            "num_links": 1,
            "num_paragraphs": 2
          },
          "input": {
            "input_file": "example.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON: Expected output schema:\n{\n  \"title\": \"string\",\n  \"num_links\": \"number\",\n  \"num_paragraphs\": \"number\"\n}",
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "7.json"
        },
        "model_output": {
          "title": "Example Domain",
          "num_links": 1,
          "num_paragraphs": 2
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "1.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999642372132,
        "cost": 0.00281598,
        "usage": {
          "input_tokens": 46813,
          "output_tokens": 30,
          "total_tokens": 46843
        },
        "latency": 4.138471841812134,
        "test_case": {
          "expected_output": {
            "insights": {
              "total_pageviews": 584,
              "total_visitors": 417
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON:\n- Total pageviews\n- Total visitors\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"total_pageviews\": number,\n    \"total_visitors\": number\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "total_pageviews": 584,
            "total_visitors": 417
          }
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "2.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0028207799999999997,
        "usage": {
          "input_tokens": 46833,
          "output_tokens": 45,
          "total_tokens": 46878
        },
        "latency": 4.492142915725708,
        "test_case": {
          "expected_output": {
            "insights": {
              "referral_sources": {
                "direct": 240,
                "twitter.com": 68,
                "news.ycombinator.com": 41
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the top 3 referral sources from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the top 3 referral sources with their pageview counts into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"referral_sources\": {\n      \"direct\": number,\n      \"twitter.com\": number,\n      \"news.ycombinator.com\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "referral_sources": {
              "direct": 240,
              "twitter.com": 68,
              "news.ycombinator.com": 41
            }
          }
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "3.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999284744263,
        "cost": 0.00281796,
        "usage": {
          "input_tokens": 46818,
          "output_tokens": 37,
          "total_tokens": 46855
        },
        "latency": 4.096934795379639,
        "test_case": {
          "expected_output": {
            "insights": {
              "device_usage": {
                "mobile": 68,
                "desktop": 32,
                "tablet": 0.7
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract device usage percentages from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the percentage breakdown of device types used into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"device_usage\": {\n      \"mobile\": number,\n      \"desktop\": number,\n      \"tablet\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "3.json"
        },
        "model_output": {
          "insights": {
            "device_usage": {
              "mobile": 68,
              "desktop": 32,
              "tablet": 0.7
            }
          }
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "4.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9764013528823853,
        "cost": 0.00645966,
        "usage": {
          "input_tokens": 107469,
          "output_tokens": 48,
          "total_tokens": 107517
        },
        "latency": 9.619225263595581,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic post information from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML content and extract the following basic post information into a JSON object:\n- Post title\n- Author name\n- Subreddit name\n- Post score\n\nFormat the output as:\n{\n \"post_title\": string,\n \"author\": string,\n \"subreddit\": string,\n \"post_score\": string\n}",
          "expected_output": {
            "post_title": "Is there a simple way to monitor Bedrock Costs?",
            "author": "Bob321423",
            "subreddit": "r/aws",
            "post_score": "5"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "4.json"
        },
        "model_output": {
          "post_title": "Is there a simple way to monitor Bedrock Costs?",
          "author": "Bob321423",
          "subreddit": "aws",
          "post_score": "5"
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "5.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9521221041679382,
        "cost": 0.006466319999999999,
        "usage": {
          "input_tokens": 107484,
          "output_tokens": 72,
          "total_tokens": 107556
        },
        "latency": 9.844396829605103,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": number,\n \"active_members\": number,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "r/aws",
            "total_members": 316355,
            "active_members": 48,
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "5.json"
        },
        "model_output": {
          "community_name": "aws",
          "total_members": 316355,
          "active_members": 48,
          "created_date": "2008-01-26T01:09:36.945Z",
          "community_type": "public"
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "1.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9642861008644104,
        "cost": 0.0028269599999999995,
        "usage": {
          "input_tokens": 46872,
          "output_tokens": 61,
          "total_tokens": 46933
        },
        "latency": 4.484634160995483,
        "test_case": {
          "expected_output": {
            "insights": {
              "top_page": {
                "url": "/blog/tone-evaluation",
                "pageviews": 296,
                "percentage_of_total": 50.5,
                "has_social_traffic": true
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze the most popular page's metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract information about the most visited page into JSON:\n- The page URL\n- Number of pageviews\n- Calculate what percentage of total pageviews this represents\n- Whether it received any social media traffic (from Twitter, Facebook, or LinkedIn)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"top_page\": {\n      \"url\": string,\n      \"pageviews\": number,\n      \"percentage_of_total\": number,\n      \"has_social_traffic\": boolean\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "top_page": {
              "url": "/blog/tone-evaluation",
              "pageviews": 296,
              "percentage_of_total": 0.506849,
              "has_social_traffic": true
            }
          }
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "2.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9776516556739807,
        "cost": 0.00282696,
        "usage": {
          "input_tokens": 46860,
          "output_tokens": 64,
          "total_tokens": 46924
        },
        "latency": 4.666141033172607,
        "test_case": {
          "expected_output": {
            "insights": {
              "mobile_stats": {
                "percentage": 68,
                "dominant_browser": "iOS Safari",
                "browser_share": 48,
                "alignment_score": 0.71
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze mobile usage patterns from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract mobile usage patterns into JSON:\n- Mobile device usage percentage\n- Most used mobile browser\n- That browser's overall share percentage\n- Calculate an alignment score (browser_share/mobile_percentage)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"mobile_stats\": {\n      \"percentage\": number,\n      \"dominant_browser\": string,\n      \"browser_share\": number,\n      \"alignment_score\": number\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "mobile_stats": {
              "percentage": 68,
              "dominant_browser": "iOS Safari",
              "browser_share": 48,
              "alignment_score": 0.7058823529411765
            }
          }
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "3.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9311821699142456,
        "cost": 0.00646896,
        "usage": {
          "input_tokens": 107476,
          "output_tokens": 85,
          "total_tokens": 107561
        },
        "latency": 10.464217901229858,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "system_prompt": "You are a data extraction assistant. Analyze comment patterns and extract comment-related metrics from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following comment information into JSON:\n- Total number of comments\n- List of all comment authors\n- Timeline of comments (how long ago each was posted)\n\nFormat the output as:\n{\n \"total_comments\": number,\n \"comment_authors\": string[],\n \"comments_timeline\": string[]\n}",
          "expected_output": {
            "total_comments": 5,
            "comment_authors": [
              "Truelikegiroux",
              "TechMktr",
              "MrPebblesMeow",
              "AdRepulsive7837",
              "noydoc"
            ],
            "comments_timeline": [
              "5 months ago",
              "5 months ago",
              "4 months ago",
              "4 months ago",
              "2 months ago"
            ]
          },
          "difficulty": "medium",
          "test_id": "3.json"
        },
        "model_output": {
          "total_comments": 5,
          "comment_authors": [
            "Truelikegiroux",
            "TechMktr",
            "MrPebblesMeow",
            "noydoc",
            "AdRepulsive7837"
          ],
          "comments_timeline": [
            "5mo ago",
            "5mo ago",
            "4mo ago",
            "4mo ago",
            "2mo ago"
          ]
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "4.json",
        "difficulty": "medium",
        "tags": [
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9688437819480896,
        "cost": 0.006462959999999999,
        "usage": {
          "input_tokens": 107484,
          "output_tokens": 58,
          "total_tokens": 107542
        },
        "latency": 9.966095924377441,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": string,\n \"active_members\": string,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "aws",
            "total_members": "316355",
            "active_members": "48",
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "4.json"
        },
        "model_output": {
          "community_name": "r/aws",
          "total_members": "316K",
          "active_members": "48",
          "created_date": "Jan 26, 2008",
          "community_type": "Public"
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "5.json",
        "difficulty": "medium",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0007542,
        "usage": {
          "input_tokens": 12102,
          "output_tokens": 117,
          "total_tokens": 12219
        },
        "latency": 1.8523120880126953,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the main logo SVG content and properties from the provided webpage HTML.",
          "user_prompt": "Please extract the main navigation logo SVG element, including its viewBox, dimensions, and path data. Don't deconstruct the paths. Store them as strings wtih the tag inside. \n\nFormat the output as JSON:\n{\n \"logo\": {\n   \"viewBox\": string,\n   \"width\": string,\n   \"height\": string,\n   \"paths\": string[]\n }\n}",
          "expected_output": {
            "logo": {
              "viewBox": "0 0 100 100",
              "width": "30px",
              "height": "30px",
              "paths": [
                "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
                "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
                "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "5.json"
        },
        "model_output": {
          "logo": {
            "viewBox": "0 0 100 100",
            "width": "30px",
            "height": "30px",
            "paths": [
              "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
              "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
              "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
            ]
          }
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "1.json",
        "difficulty": "hard",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "METADATA_EXTRACTION",
          "STRUCTURAL_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.00282894,
        "usage": {
          "input_tokens": 46873,
          "output_tokens": 69,
          "total_tokens": 46942
        },
        "latency": 4.629359006881714,
        "test_case": {
          "expected_output": {
            "insights": {
              "most_popular_page": "/blog/tone-evaluation",
              "most_popular_referral_source": "twitter.com",
              "dominant_device_type": "Mobile",
              "dominant_browser": "iOS Safari",
              "dominant_country": "United States"
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract key analytics insights from the provided webpage HTML and format them according to the specified schema.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following analytics insights into a JSON object:\n- Most visited page\n- Top referral source\n- Most common device type\n- Most used browser\n- Country with highest traffic\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"most_popular_page\": string,\n    \"most_popular_referral_source\": string,\n    \"dominant_device_type\": string,\n    \"dominant_browser\": string,\n    \"dominant_country\": string\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION",
            "METADATA_EXTRACTION",
            "STRUCTURAL_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "most_popular_page": "/blog/tone-evaluation",
            "most_popular_referral_source": "twitter.com",
            "dominant_device_type": "Mobile",
            "dominant_browser": "iOS Safari",
            "dominant_country": "United States"
          }
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "2.json",
        "difficulty": "hard",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION"
        ],
        "score": 0.24328510165214537,
        "cost": 0.00655344,
        "usage": {
          "input_tokens": 107508,
          "output_tokens": 429,
          "total_tokens": 107937
        },
        "latency": 17.329649925231934,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and organize the complete navigation structure and resource links from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following navigation structure into JSON:\n- Main resource links with their titles and URLs\n- Policy links with their titles and URLs\n- All sidebar resource links\n\nOrganize the information hierarchically and format the output as:\n{\n \"resources\": {\n   \"main_links\": [{ \"title\": string, \"url\": string }],\n   \"policies\": [{ \"title\": string, \"url\": string }],\n   \"sidebar_resources\": string[]\n }\n}",
          "expected_output": {
            "resources": {
              "main_links": [
                {
                  "title": "About Reddit",
                  "url": "https://www.redditinc.com"
                },
                {
                  "title": "Advertise",
                  "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
                },
                {
                  "title": "Help",
                  "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
                },
                {
                  "title": "Blog",
                  "url": "https://redditblog.com/"
                },
                {
                  "title": "Careers",
                  "url": "https://www.redditinc.com/careers"
                },
                {
                  "title": "Press",
                  "url": "https://www.redditinc.com/press"
                }
              ],
              "policies": [
                {
                  "title": "Content Policy",
                  "url": "https://www.redditinc.com/policies/content-policy"
                },
                {
                  "title": "Privacy Policy",
                  "url": "https://www.reddit.com/policies/privacy-policy"
                },
                {
                  "title": "User Agreement",
                  "url": "https://www.redditinc.com/policies/user-agreement"
                }
              ],
              "sidebar_resources": [
                "Amazon Web Services blog",
                "AWS status page",
                "AWS documentation",
                "AWS YouTube channel",
                "AWS Samples on GitHub",
                "AWS Labs on GitHub",
                "AWS General Reference",
                "High Scalability",
                "re:Invent Videos",
                "Workshops",
                "AWS Geek: Cloud Diagrams",
                "AWS Stash",
                "AWS Architecture Center",
                "AWS re:Post"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "2.json"
        },
        "model_output": {
          "text": "```json\n{\n  \"resources\": {\n    \"main_links\": [\n      {\n        \"title\": \"Amazon Web Services blog\",\n        \"url\": \"https://aws.amazon.com/blogs/aws/\"\n      },\n      {\n        \"title\": \"AWS status page\",\n        \"url\": \"http://status.aws.amazon.com/\"\n      },\n      {\n        \"title\": \"AWS documentation\",\n        \"url\": \"http://aws.amazon.com/documentation/\"\n      },\n      {\n        \"title\": \"AWS YouTube channel\",\n        \"url\": \"https://www.youtube.com/user/AmazonWebServices/\"\n      },\n      {\n        \"title\": \"AWS Samples on GitHub\",\n        \"url\": \"https://github.com/aws-samples\"\n      },\n      {\n        \"title\": \"AWS Labs on GitHub\",\n        \"url\": \"https://github.com/awslabs\"\n      },\n      {\n        \"title\": \"AWS General Reference\",\n        \"url\": \"https://docs.aws.amazon.com/general/latest/gr/Welcome.html\"\n      },\n      {\n        \"title\": \"High Scalability\",\n        \"url\": \"https://www.highscalability.com/\"\n      },\n      {\n        \"title\": \"re:Invent Videos\",\n        \"url\": \"https://reinventvideos.com/\"\n      },\n      {\n        \"title\": \"AWS Workshops\",\n        \"url\": \"https://workshops.aws/\"\n      },\n      {\n        \"title\": \"AWS Geek: Cloud Diagrams\",\n        \"url\": \"https://www.awsgeek.com/\"\n      },\n      {\n        \"title\": \"AWS Architecture Center\",\n        \"url\": \"https://aws.amazon.com/architecture/\"\n      },\n      {\n        \"title\": \"AWS re:Post\",\n        \"url\": \"https://repost.aws/\"\n      }\n    ],\n    \"policies\": [\n      {\n        \"title\": \"Content Policy\",\n        \"url\": \"https://www.redditinc.com/policies/content-policy\"\n      },\n      {\n        \"title\": \"Privacy Policy\",\n        \"url\": \"https://www.reddit.com/policies/privacy-policy\"\n      },\n      {\n        \"title\": \"User Agreement\",\n        \"url\": \"https://www.redditinc.com/policies/user-agreement\"\n      }\n    ],\n    \"sidebar_"
        }
      },
      {
        "model": "amazon.nova-lite-v1:0",
        "test_id": "3.json",
        "difficulty": "hard",
        "tags": [
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0007262999999999999,
        "usage": {
          "input_tokens": 12065,
          "output_tokens": 10,
          "total_tokens": 12075
        },
        "latency": 0.8214108943939209,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and decode any base64 encoded logo images from the provided webpage HTML.",
          "user_prompt": "Please analyze the HTML for any base64 encoded logo images. Extract the base64 encoded string or return empty string \n\nFormat the output as JSON:\n{\n \"encodedImage\": string\n}",
          "expected_output": {
            "encodedImage": ""
          },
          "tags": [
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "3.json"
        },
        "model_output": {
          "encodedImage": ""
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "6.json",
        "difficulty": "easy",
        "tags": [
          "METADATA_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.009949600000000001,
        "usage": {
          "input_tokens": 12081,
          "output_tokens": 89,
          "total_tokens": 12170
        },
        "latency": 2.6573469638824463,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract favicon URLs from the provided webpage HTML.",
          "user_prompt": "Please extract all favicon URLs from the HTML head section. Include any favicon references with different sizes. Format the output as a JSON array of objects with size and URL properties.\n\nFormat the output as:\n{\n \"favicons\": [{\n   \"size\": string,\n   \"url\": string\n }]\n}",
          "expected_output": {
            "favicons": [
              {
                "size": "180x180",
                "url": "/apple-touch-icon.png"
              },
              {
                "size": "32x32",
                "url": "/favicon-32x32.png"
              },
              {
                "size": "16x16",
                "url": "/favicon-16x16.png"
              }
            ]
          },
          "tags": [
            "METADATA_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "6.json"
        },
        "model_output": {
          "favicons": [
            {
              "size": "180x180",
              "url": "/apple-touch-icon.png"
            },
            {
              "size": "32x32",
              "url": "/favicon-32x32.png"
            },
            {
              "size": "16x16",
              "url": "/favicon-16x16.png"
            }
          ]
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "7.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0000000715255737,
        "cost": 0.0005344,
        "usage": {
          "input_tokens": 216,
          "output_tokens": 113,
          "total_tokens": 329
        },
        "latency": 1.8137307167053223,
        "test_case": {
          "expected_output": {
            "title": "Example Domain",
            "num_links": 1,
            "num_paragraphs": 2
          },
          "input": {
            "input_file": "example.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON: Expected output schema:\n{\n  \"title\": \"string\",\n  \"num_links\": \"number\",\n  \"num_paragraphs\": \"number\"\n}",
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "7.json"
        },
        "model_output": {
          "title": "Example Domain",
          "num_links": 1,
          "num_paragraphs": 2
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "1.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999642372132,
        "cost": 0.0375464,
        "usage": {
          "input_tokens": 46813,
          "output_tokens": 30,
          "total_tokens": 46843
        },
        "latency": 7.387508869171143,
        "test_case": {
          "expected_output": {
            "insights": {
              "total_pageviews": 584,
              "total_visitors": 417
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON:\n- Total pageviews\n- Total visitors\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"total_pageviews\": number,\n    \"total_visitors\": number\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "total_pageviews": 584,
            "total_visitors": 417
          }
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "2.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0376104,
        "usage": {
          "input_tokens": 46833,
          "output_tokens": 45,
          "total_tokens": 46878
        },
        "latency": 7.982985019683838,
        "test_case": {
          "expected_output": {
            "insights": {
              "referral_sources": {
                "direct": 240,
                "twitter.com": 68,
                "news.ycombinator.com": 41
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the top 3 referral sources from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the top 3 referral sources with their pageview counts into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"referral_sources\": {\n      \"direct\": number,\n      \"twitter.com\": number,\n      \"news.ycombinator.com\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "referral_sources": {
              "direct": 240,
              "twitter.com": 68,
              "news.ycombinator.com": 41
            }
          }
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "3.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999284744263,
        "cost": 0.037572799999999996,
        "usage": {
          "input_tokens": 46818,
          "output_tokens": 37,
          "total_tokens": 46855
        },
        "latency": 7.690171957015991,
        "test_case": {
          "expected_output": {
            "insights": {
              "device_usage": {
                "mobile": 68,
                "desktop": 32,
                "tablet": 0.7
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract device usage percentages from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the percentage breakdown of device types used into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"device_usage\": {\n      \"mobile\": number,\n      \"desktop\": number,\n      \"tablet\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "3.json"
        },
        "model_output": {
          "insights": {
            "device_usage": {
              "mobile": 68,
              "desktop": 32,
              "tablet": 0.7
            }
          }
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "4.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9764013528823853,
        "cost": 0.0861288,
        "usage": {
          "input_tokens": 107469,
          "output_tokens": 48,
          "total_tokens": 107517
        },
        "latency": 18.014215230941772,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic post information from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML content and extract the following basic post information into a JSON object:\n- Post title\n- Author name\n- Subreddit name\n- Post score\n\nFormat the output as:\n{\n \"post_title\": string,\n \"author\": string,\n \"subreddit\": string,\n \"post_score\": string\n}",
          "expected_output": {
            "post_title": "Is there a simple way to monitor Bedrock Costs?",
            "author": "Bob321423",
            "subreddit": "r/aws",
            "post_score": "5"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "4.json"
        },
        "model_output": {
          "post_title": "Is there a simple way to monitor Bedrock Costs?",
          "author": "Bob321423",
          "subreddit": "aws",
          "post_score": "5"
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "5.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9618167161941529,
        "cost": 0.0861728,
        "usage": {
          "input_tokens": 107484,
          "output_tokens": 58,
          "total_tokens": 107542
        },
        "latency": 18.333158016204834,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": number,\n \"active_members\": number,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "r/aws",
            "total_members": 316355,
            "active_members": 48,
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "5.json"
        },
        "model_output": {
          "community_name": "aws",
          "total_members": 316355,
          "active_members": 48,
          "created_date": "2008-01-26",
          "community_type": "public"
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "1.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9258349180221558,
        "cost": 0.03816,
        "usage": {
          "input_tokens": 46872,
          "output_tokens": 207,
          "total_tokens": 47079
        },
        "latency": 13.339808225631714,
        "test_case": {
          "expected_output": {
            "insights": {
              "top_page": {
                "url": "/blog/tone-evaluation",
                "pageviews": 296,
                "percentage_of_total": 50.5,
                "has_social_traffic": true
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze the most popular page's metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract information about the most visited page into JSON:\n- The page URL\n- Number of pageviews\n- Calculate what percentage of total pageviews this represents\n- Whether it received any social media traffic (from Twitter, Facebook, or LinkedIn)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"top_page\": {\n      \"url\": string,\n      \"pageviews\": number,\n      \"percentage_of_total\": number,\n      \"has_social_traffic\": boolean\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "top_page": {
              "url": "/blog/tone-evaluation",
              "pageviews": 296,
              "percentage_of_total": 50.685,
              "has_social_traffic": false
            }
          }
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "2.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9862720966339111,
        "cost": 0.0376544,
        "usage": {
          "input_tokens": 46860,
          "output_tokens": 52,
          "total_tokens": 46912
        },
        "latency": 8.180948972702026,
        "test_case": {
          "expected_output": {
            "insights": {
              "mobile_stats": {
                "percentage": 68,
                "dominant_browser": "iOS Safari",
                "browser_share": 48,
                "alignment_score": 0.71
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze mobile usage patterns from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract mobile usage patterns into JSON:\n- Mobile device usage percentage\n- Most used mobile browser\n- That browser's overall share percentage\n- Calculate an alignment score (browser_share/mobile_percentage)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"mobile_stats\": {\n      \"percentage\": number,\n      \"dominant_browser\": string,\n      \"browser_share\": number,\n      \"alignment_score\": number\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "mobile_stats": {
              "percentage": 68,
              "dominant_browser": "iOS Safari",
              "browser_share": 48,
              "alignment_score": 0.7059
            }
          }
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "3.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.930935800075531,
        "cost": 0.0862528,
        "usage": {
          "input_tokens": 107476,
          "output_tokens": 85,
          "total_tokens": 107561
        },
        "latency": 19.591431856155396,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "system_prompt": "You are a data extraction assistant. Analyze comment patterns and extract comment-related metrics from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following comment information into JSON:\n- Total number of comments\n- List of all comment authors\n- Timeline of comments (how long ago each was posted)\n\nFormat the output as:\n{\n \"total_comments\": number,\n \"comment_authors\": string[],\n \"comments_timeline\": string[]\n}",
          "expected_output": {
            "total_comments": 5,
            "comment_authors": [
              "Truelikegiroux",
              "TechMktr",
              "MrPebblesMeow",
              "AdRepulsive7837",
              "noydoc"
            ],
            "comments_timeline": [
              "5 months ago",
              "5 months ago",
              "4 months ago",
              "4 months ago",
              "2 months ago"
            ]
          },
          "difficulty": "medium",
          "test_id": "3.json"
        },
        "model_output": {
          "total_comments": 5,
          "comment_authors": [
            "Truelikegiroux",
            "TechMktr",
            "MrPebblesMeow",
            "AdRepulsive7837",
            "noydoc"
          ],
          "comments_timeline": [
            "5mo ago",
            "5mo ago",
            "4mo ago",
            "3mo ago",
            "2mo ago"
          ]
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "4.json",
        "difficulty": "medium",
        "tags": [
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.983130407333374,
        "cost": 0.0861664,
        "usage": {
          "input_tokens": 107484,
          "output_tokens": 56,
          "total_tokens": 107540
        },
        "latency": 18.24474000930786,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": string,\n \"active_members\": string,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "aws",
            "total_members": "316355",
            "active_members": "48",
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "4.json"
        },
        "model_output": {
          "community_name": "aws",
          "total_members": "316K",
          "active_members": "48",
          "created_date": "Jan 26, 2008",
          "community_type": "Public"
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "5.json",
        "difficulty": "medium",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.010056,
        "usage": {
          "input_tokens": 12102,
          "output_tokens": 117,
          "total_tokens": 12219
        },
        "latency": 2.763425827026367,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the main logo SVG content and properties from the provided webpage HTML.",
          "user_prompt": "Please extract the main navigation logo SVG element, including its viewBox, dimensions, and path data. Don't deconstruct the paths. Store them as strings wtih the tag inside. \n\nFormat the output as JSON:\n{\n \"logo\": {\n   \"viewBox\": string,\n   \"width\": string,\n   \"height\": string,\n   \"paths\": string[]\n }\n}",
          "expected_output": {
            "logo": {
              "viewBox": "0 0 100 100",
              "width": "30px",
              "height": "30px",
              "paths": [
                "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
                "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
                "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "5.json"
        },
        "model_output": {
          "logo": {
            "viewBox": "0 0 100 100",
            "width": "30px",
            "height": "30px",
            "paths": [
              "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
              "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
              "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
            ]
          }
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "1.json",
        "difficulty": "hard",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "METADATA_EXTRACTION",
          "STRUCTURAL_EXTRACTION"
        ],
        "score": 0.9391164660453797,
        "cost": 0.037712800000000005,
        "usage": {
          "input_tokens": 46873,
          "output_tokens": 67,
          "total_tokens": 46940
        },
        "latency": 8.873598098754883,
        "test_case": {
          "expected_output": {
            "insights": {
              "most_popular_page": "/blog/tone-evaluation",
              "most_popular_referral_source": "twitter.com",
              "dominant_device_type": "Mobile",
              "dominant_browser": "iOS Safari",
              "dominant_country": "United States"
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract key analytics insights from the provided webpage HTML and format them according to the specified schema.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following analytics insights into a JSON object:\n- Most visited page\n- Top referral source\n- Most common device type\n- Most used browser\n- Country with highest traffic\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"most_popular_page\": string,\n    \"most_popular_referral_source\": string,\n    \"dominant_device_type\": string,\n    \"dominant_browser\": string,\n    \"dominant_country\": string\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION",
            "METADATA_EXTRACTION",
            "STRUCTURAL_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "most_popular_page": "/blog/tone-evaluation",
            "most_popular_referral_source": "(direct)",
            "dominant_device_type": "Mobile",
            "dominant_browser": "iOS Safari",
            "dominant_country": "United States"
          }
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "2.json",
        "difficulty": "hard",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION"
        ],
        "score": 0.8424956747463771,
        "cost": 0.08726400000000001,
        "usage": {
          "input_tokens": 107508,
          "output_tokens": 393,
          "total_tokens": 107901
        },
        "latency": 29.77877187728882,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and organize the complete navigation structure and resource links from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following navigation structure into JSON:\n- Main resource links with their titles and URLs\n- Policy links with their titles and URLs\n- All sidebar resource links\n\nOrganize the information hierarchically and format the output as:\n{\n \"resources\": {\n   \"main_links\": [{ \"title\": string, \"url\": string }],\n   \"policies\": [{ \"title\": string, \"url\": string }],\n   \"sidebar_resources\": string[]\n }\n}",
          "expected_output": {
            "resources": {
              "main_links": [
                {
                  "title": "About Reddit",
                  "url": "https://www.redditinc.com"
                },
                {
                  "title": "Advertise",
                  "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
                },
                {
                  "title": "Help",
                  "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
                },
                {
                  "title": "Blog",
                  "url": "https://redditblog.com/"
                },
                {
                  "title": "Careers",
                  "url": "https://www.redditinc.com/careers"
                },
                {
                  "title": "Press",
                  "url": "https://www.redditinc.com/press"
                }
              ],
              "policies": [
                {
                  "title": "Content Policy",
                  "url": "https://www.redditinc.com/policies/content-policy"
                },
                {
                  "title": "Privacy Policy",
                  "url": "https://www.reddit.com/policies/privacy-policy"
                },
                {
                  "title": "User Agreement",
                  "url": "https://www.redditinc.com/policies/user-agreement"
                }
              ],
              "sidebar_resources": [
                "Amazon Web Services blog",
                "AWS status page",
                "AWS documentation",
                "AWS YouTube channel",
                "AWS Samples on GitHub",
                "AWS Labs on GitHub",
                "AWS General Reference",
                "High Scalability",
                "re:Invent Videos",
                "Workshops",
                "AWS Geek: Cloud Diagrams",
                "AWS Stash",
                "AWS Architecture Center",
                "AWS re:Post"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "2.json"
        },
        "model_output": {
          "resources": {
            "main_links": [
              {
                "title": "Amazon Web Services blog",
                "url": "https://aws.amazon.com/blogs/aws/"
              },
              {
                "title": "AWS status page",
                "url": "http://status.aws.amazon.com/"
              },
              {
                "title": "AWS documentation",
                "url": "http://aws.amazon.com/documentation/"
              },
              {
                "title": "AWS YouTube channel",
                "url": "https://www.youtube.com/user/AmazonWebServices/"
              },
              {
                "title": "AWS Samples",
                "url": "https://github.com/aws-samples"
              },
              {
                "title": "AWS General Reference",
                "url": "https://docs.aws.amazon.com/general/latest/gr/Welcome.html"
              },
              {
                "title": "High Scalability",
                "url": "http://www.highscalability.com/"
              },
              {
                "title": "AWS Geek",
                "url": "https://awsstash.com/"
              },
              {
                "title": "AWS Stash",
                "url": "https://awsstash.com/"
              }
            ],
            "policies": [
              {
                "title": "Content Policy",
                "url": "https://www.redditinc.com/policies/content-policy"
              },
              {
                "title": "Privacy Policy",
                "url": "https://www.redditinc.com/policies/privacy-policy"
              },
              {
                "title": "User Agreement",
                "url": "https://www.redditinc.com/policies/user-agreement"
              }
            ],
            "sidebar_resources": [
              "https://www.reddit.com/message/compose/?to=%2Fr%2Faws&amp;subject=sidebar+tweaks",
              "https://www.reddit.com/r/rehabilitation/wiki/faq"
            ]
          }
        }
      },
      {
        "model": "amazon.nova-pro-v1:0",
        "test_id": "3.json",
        "difficulty": "hard",
        "tags": [
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.009684000000000002,
        "usage": {
          "input_tokens": 12065,
          "output_tokens": 10,
          "total_tokens": 12075
        },
        "latency": 0.9488499164581299,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and decode any base64 encoded logo images from the provided webpage HTML.",
          "user_prompt": "Please analyze the HTML for any base64 encoded logo images. Extract the base64 encoded string or return empty string \n\nFormat the output as JSON:\n{\n \"encodedImage\": string\n}",
          "expected_output": {
            "encodedImage": ""
          },
          "tags": [
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "3.json"
        },
        "model_output": {
          "encodedImage": ""
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "6.json",
        "difficulty": "easy",
        "tags": [
          "METADATA_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.01591875,
        "usage": {
          "input_tokens": 12419,
          "output_tokens": 79,
          "total_tokens": 12498
        },
        "latency": 3.3887500762939453,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract favicon URLs from the provided webpage HTML.",
          "user_prompt": "Please extract all favicon URLs from the HTML head section. Include any favicon references with different sizes. Format the output as a JSON array of objects with size and URL properties.\n\nFormat the output as:\n{\n \"favicons\": [{\n   \"size\": string,\n   \"url\": string\n }]\n}",
          "expected_output": {
            "favicons": [
              {
                "size": "180x180",
                "url": "/apple-touch-icon.png"
              },
              {
                "size": "32x32",
                "url": "/favicon-32x32.png"
              },
              {
                "size": "16x16",
                "url": "/favicon-16x16.png"
              }
            ]
          },
          "tags": [
            "METADATA_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "6.json"
        },
        "model_output": {
          "favicons": [
            {
              "size": "180x180",
              "url": "/apple-touch-icon.png"
            },
            {
              "size": "32x32",
              "url": "/favicon-32x32.png"
            },
            {
              "size": "16x16",
              "url": "/favicon-16x16.png"
            }
          ]
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "7.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0000000715255737,
        "cost": 0.00039999999999999996,
        "usage": {
          "input_tokens": 228,
          "output_tokens": 23,
          "total_tokens": 251
        },
        "latency": 1.0657079219818115,
        "test_case": {
          "expected_output": {
            "title": "Example Domain",
            "num_links": 1,
            "num_paragraphs": 2
          },
          "input": {
            "input_file": "example.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON: Expected output schema:\n{\n  \"title\": \"string\",\n  \"num_links\": \"number\",\n  \"num_paragraphs\": \"number\"\n}",
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "7.json"
        },
        "model_output": {
          "title": "Example Domain",
          "num_links": 1,
          "num_paragraphs": 2
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "1.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999642372132,
        "cost": 0.05865625000000001,
        "usage": {
          "input_tokens": 46829,
          "output_tokens": 24,
          "total_tokens": 46853
        },
        "latency": 2.5470988750457764,
        "test_case": {
          "expected_output": {
            "insights": {
              "total_pageviews": 584,
              "total_visitors": 417
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON:\n- Total pageviews\n- Total visitors\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"total_pageviews\": number,\n    \"total_visitors\": number\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "total_pageviews": 584,
            "total_visitors": 417
          }
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "2.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.05875375,
        "usage": {
          "input_tokens": 46851,
          "output_tokens": 38,
          "total_tokens": 46889
        },
        "latency": 2.97953200340271,
        "test_case": {
          "expected_output": {
            "insights": {
              "referral_sources": {
                "direct": 240,
                "twitter.com": 68,
                "news.ycombinator.com": 41
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the top 3 referral sources from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the top 3 referral sources with their pageview counts into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"referral_sources\": {\n      \"direct\": number,\n      \"twitter.com\": number,\n      \"news.ycombinator.com\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "referral_sources": {
              "direct": 240,
              "twitter.com": 68,
              "news.ycombinator.com": 41
            }
          }
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "3.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999284744263,
        "cost": 0.058695,
        "usage": {
          "input_tokens": 46836,
          "output_tokens": 30,
          "total_tokens": 46866
        },
        "latency": 2.6941258907318115,
        "test_case": {
          "expected_output": {
            "insights": {
              "device_usage": {
                "mobile": 68,
                "desktop": 32,
                "tablet": 0.7
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract device usage percentages from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the percentage breakdown of device types used into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"device_usage\": {\n      \"mobile\": number,\n      \"desktop\": number,\n      \"tablet\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "3.json"
        },
        "model_output": {
          "insights": {
            "device_usage": {
              "mobile": 68,
              "desktop": 32,
              "tablet": 0.7
            }
          }
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "4.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9764013528823853,
        "cost": 0.133035,
        "usage": {
          "input_tokens": 106260,
          "output_tokens": 42,
          "total_tokens": 106302
        },
        "latency": 4.6708598136901855,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic post information from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML content and extract the following basic post information into a JSON object:\n- Post title\n- Author name\n- Subreddit name\n- Post score\n\nFormat the output as:\n{\n \"post_title\": string,\n \"author\": string,\n \"subreddit\": string,\n \"post_score\": string\n}",
          "expected_output": {
            "post_title": "Is there a simple way to monitor Bedrock Costs?",
            "author": "Bob321423",
            "subreddit": "r/aws",
            "post_score": "5"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "4.json"
        },
        "model_output": {
          "post_title": "Is there a simple way to monitor Bedrock Costs?",
          "author": "Bob321423",
          "subreddit": "aws",
          "post_score": "5"
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "5.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9491687417030334,
        "cost": 0.13322374999999997,
        "usage": {
          "input_tokens": 106275,
          "output_tokens": 76,
          "total_tokens": 106351
        },
        "latency": 5.387101888656616,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": number,\n \"active_members\": number,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "r/aws",
            "total_members": 316355,
            "active_members": 48,
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "5.json"
        },
        "model_output": {
          "community_name": "aws",
          "total_members": 316355,
          "active_members": 48,
          "created_date": "2008-01-26T01:09:36.945000+0000",
          "community_type": "public"
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "1.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9820192575454711,
        "cost": 0.05886875,
        "usage": {
          "input_tokens": 46895,
          "output_tokens": 50,
          "total_tokens": 46945
        },
        "latency": 3.315152883529663,
        "test_case": {
          "expected_output": {
            "insights": {
              "top_page": {
                "url": "/blog/tone-evaluation",
                "pageviews": 296,
                "percentage_of_total": 50.5,
                "has_social_traffic": true
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze the most popular page's metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract information about the most visited page into JSON:\n- The page URL\n- Number of pageviews\n- Calculate what percentage of total pageviews this represents\n- Whether it received any social media traffic (from Twitter, Facebook, or LinkedIn)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"top_page\": {\n      \"url\": string,\n      \"pageviews\": number,\n      \"percentage_of_total\": number,\n      \"has_social_traffic\": boolean\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "top_page": {
              "url": "/blog/tone-evaluation",
              "pageviews": 296,
              "percentage_of_total": 50.68,
              "has_social_traffic": true
            }
          }
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "2.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.8876103281974792,
        "cost": 0.05891125,
        "usage": {
          "input_tokens": 46881,
          "output_tokens": 62,
          "total_tokens": 46943
        },
        "latency": 3.630920886993408,
        "test_case": {
          "expected_output": {
            "insights": {
              "mobile_stats": {
                "percentage": 68,
                "dominant_browser": "iOS Safari",
                "browser_share": 48,
                "alignment_score": 0.71
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze mobile usage patterns from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract mobile usage patterns into JSON:\n- Mobile device usage percentage\n- Most used mobile browser\n- That browser's overall share percentage\n- Calculate an alignment score (browser_share/mobile_percentage)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"mobile_stats\": {\n      \"percentage\": number,\n      \"dominant_browser\": string,\n      \"browser_share\": number,\n      \"alignment_score\": number\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "mobile_stats": {
              "percentage": 0.68,
              "dominant_browser": "iOS Safari",
              "browser_share": 0.48,
              "alignment_score": 0.7058823529411765
            }
          }
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "3.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9311822414398193,
        "cost": 0.13319875,
        "usage": {
          "input_tokens": 106267,
          "output_tokens": 73,
          "total_tokens": 106340
        },
        "latency": 5.985762119293213,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "system_prompt": "You are a data extraction assistant. Analyze comment patterns and extract comment-related metrics from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following comment information into JSON:\n- Total number of comments\n- List of all comment authors\n- Timeline of comments (how long ago each was posted)\n\nFormat the output as:\n{\n \"total_comments\": number,\n \"comment_authors\": string[],\n \"comments_timeline\": string[]\n}",
          "expected_output": {
            "total_comments": 5,
            "comment_authors": [
              "Truelikegiroux",
              "TechMktr",
              "MrPebblesMeow",
              "AdRepulsive7837",
              "noydoc"
            ],
            "comments_timeline": [
              "5 months ago",
              "5 months ago",
              "4 months ago",
              "4 months ago",
              "2 months ago"
            ]
          },
          "difficulty": "medium",
          "test_id": "3.json"
        },
        "model_output": {
          "total_comments": 5,
          "comment_authors": [
            "Truelikegiroux",
            "TechMktr",
            "MrPebblesMeow",
            "AdRepulsive7837",
            "noydoc"
          ],
          "comments_timeline": [
            "5mo ago",
            "5mo ago",
            "4mo ago",
            "4mo ago",
            "2mo ago"
          ]
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "4.json",
        "difficulty": "medium",
        "tags": [
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9849911093711853,
        "cost": 0.13312875,
        "usage": {
          "input_tokens": 106275,
          "output_tokens": 57,
          "total_tokens": 106332
        },
        "latency": 5.17057728767395,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": string,\n \"active_members\": string,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "aws",
            "total_members": "316355",
            "active_members": "48",
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "4.json"
        },
        "model_output": {
          "community_name": "r/aws",
          "total_members": "316355",
          "active_members": "48",
          "created_date": "Jan 26, 2008",
          "community_type": "public"
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "5.json",
        "difficulty": "medium",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.016116250000000002,
        "usage": {
          "input_tokens": 12441,
          "output_tokens": 113,
          "total_tokens": 12554
        },
        "latency": 3.49928617477417,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the main logo SVG content and properties from the provided webpage HTML.",
          "user_prompt": "Please extract the main navigation logo SVG element, including its viewBox, dimensions, and path data. Don't deconstruct the paths. Store them as strings wtih the tag inside. \n\nFormat the output as JSON:\n{\n \"logo\": {\n   \"viewBox\": string,\n   \"width\": string,\n   \"height\": string,\n   \"paths\": string[]\n }\n}",
          "expected_output": {
            "logo": {
              "viewBox": "0 0 100 100",
              "width": "30px",
              "height": "30px",
              "paths": [
                "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
                "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
                "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "5.json"
        },
        "model_output": {
          "logo": {
            "viewBox": "0 0 100 100",
            "width": "30px",
            "height": "30px",
            "paths": [
              "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
              "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
              "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
            ]
          }
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "1.json",
        "difficulty": "hard",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "METADATA_EXTRACTION",
          "STRUCTURAL_EXTRACTION"
        ],
        "score": 0.9245992064476013,
        "cost": 0.05889375000000001,
        "usage": {
          "input_tokens": 46891,
          "output_tokens": 56,
          "total_tokens": 46947
        },
        "latency": 3.5489089488983154,
        "test_case": {
          "expected_output": {
            "insights": {
              "most_popular_page": "/blog/tone-evaluation",
              "most_popular_referral_source": "twitter.com",
              "dominant_device_type": "Mobile",
              "dominant_browser": "iOS Safari",
              "dominant_country": "United States"
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract key analytics insights from the provided webpage HTML and format them according to the specified schema.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following analytics insights into a JSON object:\n- Most visited page\n- Top referral source\n- Most common device type\n- Most used browser\n- Country with highest traffic\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"most_popular_page\": string,\n    \"most_popular_referral_source\": string,\n    \"dominant_device_type\": string,\n    \"dominant_browser\": string,\n    \"dominant_country\": string\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION",
            "METADATA_EXTRACTION",
            "STRUCTURAL_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "most_popular_page": "/blog/tone-evaluation",
            "most_popular_referral_source": "(direct)",
            "dominant_device_type": "mobile",
            "dominant_browser": "iOS Safari",
            "dominant_country": "US"
          }
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "2.json",
        "difficulty": "hard",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION"
        ],
        "score": 0.6518151728312174,
        "cost": 0.13756375,
        "usage": {
          "input_tokens": 106299,
          "output_tokens": 938,
          "total_tokens": 107237
        },
        "latency": 41.30688810348511,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and organize the complete navigation structure and resource links from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following navigation structure into JSON:\n- Main resource links with their titles and URLs\n- Policy links with their titles and URLs\n- All sidebar resource links\n\nOrganize the information hierarchically and format the output as:\n{\n \"resources\": {\n   \"main_links\": [{ \"title\": string, \"url\": string }],\n   \"policies\": [{ \"title\": string, \"url\": string }],\n   \"sidebar_resources\": string[]\n }\n}",
          "expected_output": {
            "resources": {
              "main_links": [
                {
                  "title": "About Reddit",
                  "url": "https://www.redditinc.com"
                },
                {
                  "title": "Advertise",
                  "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
                },
                {
                  "title": "Help",
                  "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
                },
                {
                  "title": "Blog",
                  "url": "https://redditblog.com/"
                },
                {
                  "title": "Careers",
                  "url": "https://www.redditinc.com/careers"
                },
                {
                  "title": "Press",
                  "url": "https://www.redditinc.com/press"
                }
              ],
              "policies": [
                {
                  "title": "Content Policy",
                  "url": "https://www.redditinc.com/policies/content-policy"
                },
                {
                  "title": "Privacy Policy",
                  "url": "https://www.reddit.com/policies/privacy-policy"
                },
                {
                  "title": "User Agreement",
                  "url": "https://www.redditinc.com/policies/user-agreement"
                }
              ],
              "sidebar_resources": [
                "Amazon Web Services blog",
                "AWS status page",
                "AWS documentation",
                "AWS YouTube channel",
                "AWS Samples on GitHub",
                "AWS Labs on GitHub",
                "AWS General Reference",
                "High Scalability",
                "re:Invent Videos",
                "Workshops",
                "AWS Geek: Cloud Diagrams",
                "AWS Stash",
                "AWS Architecture Center",
                "AWS re:Post"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "2.json"
        },
        "model_output": {
          "resources": {
            "main_links": [
              {
                "title": "Home",
                "url": "/"
              },
              {
                "title": "Search in r/aws",
                "url": "/r/aws/search/?q="
              },
              {
                "title": "Advertise on Reddit",
                "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=nav_cta"
              },
              {
                "title": "Create post",
                "url": "/r/aws/submit"
              },
              {
                "title": "View Profile",
                "url": "/user/peytoncasper/"
              },
              {
                "title": "Edit Avatar",
                "url": "https://reddit.com/avatar"
              },
              {
                "title": "Achievements",
                "url": "/user/peytoncasper/achievements"
              },
              {
                "title": "Contributor Program",
                "url": "/contributor-program/profile"
              },
              {
                "title": "Premium",
                "url": "/premium"
              },
              {
                "title": "Settings",
                "url": "/settings/"
              },
              {
                "title": "Advertise on Reddit",
                "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=user_menu_cta"
              },
              {
                "title": "r/aws",
                "url": "/r/aws/"
              },
              {
                "title": "aws",
                "url": "/r/aws/"
              },
              {
                "title": "Bob321423",
                "url": "/user/Bob321423/"
              },
              {
                "title": "technical question",
                "url": "/r/aws/?f=flair_name%3A%22technical%20question%22"
              },
              {
                "title": "Truelikegiroux",
                "url": "/user/Truelikegiroux/"
              },
              {
                "title": "Truelikegiroux's profile",
                "url": "/user/Truelikegiroux/"
              },
              {
                "title": "TechMktr",
                "url": "/user/TechMktr/"
              },
              {
                "title": "TechMktr's profile",
                "url": "/user/TechMktr/"
              },
              {
                "title": "MrPebblesMeow",
                "url": "/user/MrPebblesMeow/"
              },
              {
                "title": "MrPebblesMeow's profile",
                "url": "/user/MrPebblesMeow/"
              },
              {
                "title": "AdRepulsive7837",
                "url": "/user/AdRepulsive7837/"
              },
              {
                "title": "AdRepulsive7837's profile",
                "url": "/user/AdRepulsive7837/"
              },
              {
                "title": "noydoc",
                "url": "/user/noydoc/"
              },
              {
                "title": "noydoc's profile",
                "url": "/user/noydoc/"
              }
            ],
            "policies": [
              {
                "title": "Content Policy",
                "url": "https://www.redditinc.com/policies/content-policy"
              },
              {
                "title": "Privacy Policy",
                "url": "https://www.reddit.com/policies/privacy-policy"
              },
              {
                "title": "User Agreement",
                "url": "https://www.redditinc.com/policies/user-agreement"
              }
            ],
            "sidebar_resources": [
              "https://aws.amazon.com/blogs/aws/",
              "http://status.aws.amazon.com/",
              "http://aws.amazon.com/documentation/",
              "https://www.youtube.com/user/AmazonWebServices/",
              "https://github.com/aws-samples",
              "https://github.com/awslabs",
              "https://docs.aws.amazon.com/general/latest/gr/Welcome.html",
              "http://www.highscalability.com/",
              "https://reinventvideos.com/",
              "https://workshops.aws/",
              "https://www.awsgeek.com/",
              "https://awsstash.com/",
              "https://aws.amazon.com/architecture/",
              "https://repost.aws/",
              "/r/AWScertifications",
              "/r/virtualization",
              "/r/devops",
              "/r/kubernetes",
              "/r/terraform",
              "/r/cloudcomputing",
              "/r/bigdata",
              "/r/vmware",
              "/r/networking",
              "/r/sysadmin",
              "/r/netsec",
              "/r/aws_cdk",
              "/r/AWSCloudFormation",
              "http://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=sidebar+tweaks+-+aws",
              "https://www.reddit.com/r/rehabilitation/wiki/faq"
            ]
          }
        }
      },
      {
        "model": "gemini-1.5-pro",
        "test_id": "3.json",
        "difficulty": "hard",
        "tags": [
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.015525,
        "usage": {
          "input_tokens": 12400,
          "output_tokens": 5,
          "total_tokens": 12405
        },
        "latency": 1.2777140140533447,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and decode any base64 encoded logo images from the provided webpage HTML.",
          "user_prompt": "Please analyze the HTML for any base64 encoded logo images. Extract the base64 encoded string or return empty string \n\nFormat the output as JSON:\n{\n \"encodedImage\": string\n}",
          "expected_output": {
            "encodedImage": ""
          },
          "tags": [
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "3.json"
        },
        "model_output": {
          "encodedImage": ""
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "6.json",
        "difficulty": "easy",
        "tags": [
          "METADATA_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.00047756249999999996,
        "usage": {
          "input_tokens": 12419,
          "output_tokens": 79,
          "total_tokens": 12498
        },
        "latency": 1.112060308456421,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract favicon URLs from the provided webpage HTML.",
          "user_prompt": "Please extract all favicon URLs from the HTML head section. Include any favicon references with different sizes. Format the output as a JSON array of objects with size and URL properties.\n\nFormat the output as:\n{\n \"favicons\": [{\n   \"size\": string,\n   \"url\": string\n }]\n}",
          "expected_output": {
            "favicons": [
              {
                "size": "180x180",
                "url": "/apple-touch-icon.png"
              },
              {
                "size": "32x32",
                "url": "/favicon-32x32.png"
              },
              {
                "size": "16x16",
                "url": "/favicon-16x16.png"
              }
            ]
          },
          "tags": [
            "METADATA_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "6.json"
        },
        "model_output": {
          "favicons": [
            {
              "size": "180x180",
              "url": "/apple-touch-icon.png"
            },
            {
              "size": "32x32",
              "url": "/favicon-32x32.png"
            },
            {
              "size": "16x16",
              "url": "/favicon-16x16.png"
            }
          ]
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "7.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0000000715255737,
        "cost": 1.2e-05,
        "usage": {
          "input_tokens": 228,
          "output_tokens": 23,
          "total_tokens": 251
        },
        "latency": 0.5646567344665527,
        "test_case": {
          "expected_output": {
            "title": "Example Domain",
            "num_links": 1,
            "num_paragraphs": 2
          },
          "input": {
            "input_file": "example.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON: Expected output schema:\n{\n  \"title\": \"string\",\n  \"num_links\": \"number\",\n  \"num_paragraphs\": \"number\"\n}",
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "7.json"
        },
        "model_output": {
          "title": "Example Domain",
          "num_links": 1,
          "num_paragraphs": 2
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "1.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999642372132,
        "cost": 0.0017596875000000002,
        "usage": {
          "input_tokens": 46829,
          "output_tokens": 24,
          "total_tokens": 46853
        },
        "latency": 2.0691330432891846,
        "test_case": {
          "expected_output": {
            "insights": {
              "total_pageviews": 584,
              "total_visitors": 417
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON:\n- Total pageviews\n- Total visitors\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"total_pageviews\": number,\n    \"total_visitors\": number\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "total_pageviews": "584",
            "total_visitors": "417"
          }
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "2.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0017626124999999997,
        "usage": {
          "input_tokens": 46851,
          "output_tokens": 38,
          "total_tokens": 46889
        },
        "latency": 2.311692953109741,
        "test_case": {
          "expected_output": {
            "insights": {
              "referral_sources": {
                "direct": 240,
                "twitter.com": 68,
                "news.ycombinator.com": 41
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the top 3 referral sources from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the top 3 referral sources with their pageview counts into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"referral_sources\": {\n      \"direct\": number,\n      \"twitter.com\": number,\n      \"news.ycombinator.com\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "referral_sources": {
              "direct": 240,
              "twitter.com": 68,
              "news.ycombinator.com": 41
            }
          }
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "3.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999284744263,
        "cost": 0.00176085,
        "usage": {
          "input_tokens": 46836,
          "output_tokens": 30,
          "total_tokens": 46866
        },
        "latency": 2.166278123855591,
        "test_case": {
          "expected_output": {
            "insights": {
              "device_usage": {
                "mobile": 68,
                "desktop": 32,
                "tablet": 0.7
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract device usage percentages from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the percentage breakdown of device types used into JSON.\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"device_usage\": {\n      \"mobile\": number,\n      \"desktop\": number,\n      \"tablet\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "3.json"
        },
        "model_output": {
          "insights": {
            "device_usage": {
              "mobile": 68,
              "desktop": 32,
              "tablet": 0.7
            }
          }
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "4.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9751253724098206,
        "cost": 0.003991799999999999,
        "usage": {
          "input_tokens": 106260,
          "output_tokens": 47,
          "total_tokens": 106307
        },
        "latency": 3.998295783996582,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic post information from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML content and extract the following basic post information into a JSON object:\n- Post title\n- Author name\n- Subreddit name\n- Post score\n\nFormat the output as:\n{\n \"post_title\": string,\n \"author\": string,\n \"subreddit\": string,\n \"post_score\": string\n}",
          "expected_output": {
            "post_title": "Is there a simple way to monitor Bedrock Costs?",
            "author": "Bob321423",
            "subreddit": "r/aws",
            "post_score": "5"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "4.json"
        },
        "model_output": {
          "post_title": "Is there a simple way to monitor Bedrock Costs? : r/aws",
          "author": "Bob321423",
          "subreddit": "aws",
          "post_score": "5"
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "5.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9849911093711853,
        "cost": 0.003993562499999999,
        "usage": {
          "input_tokens": 106275,
          "output_tokens": 55,
          "total_tokens": 106330
        },
        "latency": 4.047276973724365,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": number,\n \"active_members\": number,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "r/aws",
            "total_members": 316355,
            "active_members": 48,
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "5.json"
        },
        "model_output": {
          "community_name": "aws",
          "total_members": 316355,
          "active_members": 48,
          "created_date": "Jan 26, 2008",
          "community_type": "public"
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "1.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9286970853805542,
        "cost": 0.0017689124999999998,
        "usage": {
          "input_tokens": 46895,
          "output_tokens": 69,
          "total_tokens": 46964
        },
        "latency": 2.5794131755828857,
        "test_case": {
          "expected_output": {
            "insights": {
              "top_page": {
                "url": "/blog/tone-evaluation",
                "pageviews": 296,
                "percentage_of_total": 50.5,
                "has_social_traffic": true
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze the most popular page's metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract information about the most visited page into JSON:\n- The page URL\n- Number of pageviews\n- Calculate what percentage of total pageviews this represents\n- Whether it received any social media traffic (from Twitter, Facebook, or LinkedIn)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"top_page\": {\n      \"url\": string,\n      \"pageviews\": number,\n      \"percentage_of_total\": number,\n      \"has_social_traffic\": boolean\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "top_page": {
              "url": "/peytoncasper.com/blog/tone-evaluation",
              "pageviews": 296,
              "percentage_of_total": 50.85614754098361,
              "has_social_traffic": true
            }
          }
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "2.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9776516556739807,
        "cost": 0.0017667374999999997,
        "usage": {
          "input_tokens": 46881,
          "output_tokens": 58,
          "total_tokens": 46939
        },
        "latency": 2.416213035583496,
        "test_case": {
          "expected_output": {
            "insights": {
              "mobile_stats": {
                "percentage": 68,
                "dominant_browser": "iOS Safari",
                "browser_share": 48,
                "alignment_score": 0.71
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze mobile usage patterns from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract mobile usage patterns into JSON:\n- Mobile device usage percentage\n- Most used mobile browser\n- That browser's overall share percentage\n- Calculate an alignment score (browser_share/mobile_percentage)\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"mobile_stats\": {\n      \"percentage\": number,\n      \"dominant_browser\": string,\n      \"browser_share\": number,\n      \"alignment_score\": number\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "mobile_stats": {
              "percentage": 68,
              "dominant_browser": "iOS Safari",
              "browser_share": 48,
              "alignment_score": 0.7058823529411765
            }
          }
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "3.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9311822414398193,
        "cost": 0.0039959625,
        "usage": {
          "input_tokens": 106267,
          "output_tokens": 73,
          "total_tokens": 106340
        },
        "latency": 4.052549839019775,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "system_prompt": "You are a data extraction assistant. Analyze comment patterns and extract comment-related metrics from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following comment information into JSON:\n- Total number of comments\n- List of all comment authors\n- Timeline of comments (how long ago each was posted)\n\nFormat the output as:\n{\n \"total_comments\": number,\n \"comment_authors\": string[],\n \"comments_timeline\": string[]\n}",
          "expected_output": {
            "total_comments": 5,
            "comment_authors": [
              "Truelikegiroux",
              "TechMktr",
              "MrPebblesMeow",
              "AdRepulsive7837",
              "noydoc"
            ],
            "comments_timeline": [
              "5 months ago",
              "5 months ago",
              "4 months ago",
              "4 months ago",
              "2 months ago"
            ]
          },
          "difficulty": "medium",
          "test_id": "3.json"
        },
        "model_output": {
          "total_comments": "5",
          "comment_authors": [
            "Truelikegiroux",
            "TechMktr",
            "MrPebblesMeow",
            "AdRepulsive7837",
            "noydoc"
          ],
          "comments_timeline": [
            "5mo ago",
            "5mo ago",
            "4mo ago",
            "4mo ago",
            "2mo ago"
          ]
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "4.json",
        "difficulty": "medium",
        "tags": [
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999642372132,
        "cost": 0.003993562499999999,
        "usage": {
          "input_tokens": 106275,
          "output_tokens": 55,
          "total_tokens": 106330
        },
        "latency": 3.8568692207336426,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nFormat the output as:\n{\n \"community_name\": string,\n \"total_members\": string,\n \"active_members\": string,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "aws",
            "total_members": "316355",
            "active_members": "48",
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "4.json"
        },
        "model_output": {
          "community_name": "aws",
          "total_members": "316355",
          "active_members": "48",
          "created_date": "Jan 26, 2008",
          "community_type": "public"
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "5.json",
        "difficulty": "medium",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0004834875,
        "usage": {
          "input_tokens": 12441,
          "output_tokens": 113,
          "total_tokens": 12554
        },
        "latency": 1.2369070053100586,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the main logo SVG content and properties from the provided webpage HTML.",
          "user_prompt": "Please extract the main navigation logo SVG element, including its viewBox, dimensions, and path data. Don't deconstruct the paths. Store them as strings wtih the tag inside. \n\nFormat the output as JSON:\n{\n \"logo\": {\n   \"viewBox\": string,\n   \"width\": string,\n   \"height\": string,\n   \"paths\": string[]\n }\n}",
          "expected_output": {
            "logo": {
              "viewBox": "0 0 100 100",
              "width": "30px",
              "height": "30px",
              "paths": [
                "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
                "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
                "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "5.json"
        },
        "model_output": {
          "logo": {
            "viewBox": "0 0 100 100",
            "width": "30px",
            "height": "30px",
            "paths": [
              "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
              "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
              "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
            ]
          }
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "1.json",
        "difficulty": "hard",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "METADATA_EXTRACTION",
          "STRUCTURAL_EXTRACTION"
        ],
        "score": 0.9391164660453797,
        "cost": 0.0017669625,
        "usage": {
          "input_tokens": 46891,
          "output_tokens": 57,
          "total_tokens": 46948
        },
        "latency": 2.433231830596924,
        "test_case": {
          "expected_output": {
            "insights": {
              "most_popular_page": "/blog/tone-evaluation",
              "most_popular_referral_source": "twitter.com",
              "dominant_device_type": "Mobile",
              "dominant_browser": "iOS Safari",
              "dominant_country": "United States"
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract key analytics insights from the provided webpage HTML and format them according to the specified schema.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following analytics insights into a JSON object:\n- Most visited page\n- Top referral source\n- Most common device type\n- Most used browser\n- Country with highest traffic\n\nFormat the output according to this schema:\n{\n  \"insights\": {\n    \"most_popular_page\": string,\n    \"most_popular_referral_source\": string,\n    \"dominant_device_type\": string,\n    \"dominant_browser\": string,\n    \"dominant_country\": string\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION",
            "METADATA_EXTRACTION",
            "STRUCTURAL_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "most_popular_page": "/blog/tone-evaluation",
            "most_popular_referral_source": "(direct)",
            "dominant_device_type": "Mobile",
            "dominant_browser": "iOS Safari",
            "dominant_country": "United States"
          }
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "2.json",
        "difficulty": "hard",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION"
        ],
        "score": 0.7410698825662786,
        "cost": 0.0040453125,
        "usage": {
          "input_tokens": 106299,
          "output_tokens": 394,
          "total_tokens": 106693
        },
        "latency": 7.17159104347229,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and organize the complete navigation structure and resource links from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following navigation structure into JSON:\n- Main resource links with their titles and URLs\n- Policy links with their titles and URLs\n- All sidebar resource links\n\nOrganize the information hierarchically and format the output as:\n{\n \"resources\": {\n   \"main_links\": [{ \"title\": string, \"url\": string }],\n   \"policies\": [{ \"title\": string, \"url\": string }],\n   \"sidebar_resources\": string[]\n }\n}",
          "expected_output": {
            "resources": {
              "main_links": [
                {
                  "title": "About Reddit",
                  "url": "https://www.redditinc.com"
                },
                {
                  "title": "Advertise",
                  "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
                },
                {
                  "title": "Help",
                  "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
                },
                {
                  "title": "Blog",
                  "url": "https://redditblog.com/"
                },
                {
                  "title": "Careers",
                  "url": "https://www.redditinc.com/careers"
                },
                {
                  "title": "Press",
                  "url": "https://www.redditinc.com/press"
                }
              ],
              "policies": [
                {
                  "title": "Content Policy",
                  "url": "https://www.redditinc.com/policies/content-policy"
                },
                {
                  "title": "Privacy Policy",
                  "url": "https://www.reddit.com/policies/privacy-policy"
                },
                {
                  "title": "User Agreement",
                  "url": "https://www.redditinc.com/policies/user-agreement"
                }
              ],
              "sidebar_resources": [
                "Amazon Web Services blog",
                "AWS status page",
                "AWS documentation",
                "AWS YouTube channel",
                "AWS Samples on GitHub",
                "AWS Labs on GitHub",
                "AWS General Reference",
                "High Scalability",
                "re:Invent Videos",
                "Workshops",
                "AWS Geek: Cloud Diagrams",
                "AWS Stash",
                "AWS Architecture Center",
                "AWS re:Post"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "2.json"
        },
        "model_output": {
          "resources": {
            "main_links": [
              {
                "title": "Home",
                "url": "/"
              }
            ],
            "policies": [
              {
                "title": "Content Policy",
                "url": "https://www.redditinc.com/policies/content-policy"
              },
              {
                "title": "Privacy Policy",
                "url": "https://www.reddit.com/policies/privacy-policy"
              },
              {
                "title": "User Agreement",
                "url": "https://www.redditinc.com/policies/user-agreement"
              }
            ],
            "sidebar_resources": [
              "https://aws.amazon.com/blogs/aws/",
              "http://status.aws.amazon.com/",
              "http://aws.amazon.com/documentation/",
              "https://www.youtube.com/user/AmazonWebServices/",
              "https://github.com/aws-samples",
              "https://github.com/awslabs",
              "https://docs.aws.amazon.com/general/latest/gr/Welcome.html",
              "http://www.highscalability.com/",
              "https://reinventvideos.com/",
              "https://workshops.aws/",
              "https://www.awsgeek.com/",
              "https://awsstash.com/",
              "https://aws.amazon.com/architecture/",
              "https://repost.aws/",
              "/r/AWScertifications",
              "/r/virtualization",
              "/r/devops",
              "/r/kubernetes",
              "/r/terraform",
              "/r/cloudcomputing",
              "/r/bigdata",
              "/r/vmware",
              "/r/networking",
              "/r/sysadmin",
              "/r/netsec",
              "/r/aws_cdk",
              "/r/AWSCloudFormation",
              "http://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=sidebar+tweaks+-+aws",
              "https://www.reddit.com/r/rehabilitation/wiki/faq"
            ]
          }
        }
      },
      {
        "model": "gemini-1.5-flash-002",
        "test_id": "3.json",
        "difficulty": "hard",
        "tags": [
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.00046574999999999996,
        "usage": {
          "input_tokens": 12400,
          "output_tokens": 5,
          "total_tokens": 12405
        },
        "latency": 0.8049337863922119,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and decode any base64 encoded logo images from the provided webpage HTML.",
          "user_prompt": "Please analyze the HTML for any base64 encoded logo images. Extract the base64 encoded string or return empty string \n\nFormat the output as JSON:\n{\n \"encodedImage\": string\n}",
          "expected_output": {
            "encodedImage": ""
          },
          "tags": [
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "3.json"
        },
        "model_output": {
          "encodedImage": ""
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "6.json",
        "difficulty": "easy",
        "tags": [
          "METADATA_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0028002500000000002,
        "usage": {
          "input_tokens": 10661,
          "output_tokens": 108,
          "total_tokens": 10769
        },
        "latency": 4.723471164703369,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract favicon URLs from the provided webpage HTML.",
          "user_prompt": "Please extract all favicon URLs from the HTML head section. Include any favicon references with different sizes. Format the output as a JSON array of objects with size and URL properties.\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"favicons\": [{\n   \"size\": string,\n   \"url\": string\n }]\n}",
          "expected_output": {
            "favicons": [
              {
                "size": "180x180",
                "url": "/apple-touch-icon.png"
              },
              {
                "size": "32x32",
                "url": "/favicon-32x32.png"
              },
              {
                "size": "16x16",
                "url": "/favicon-16x16.png"
              }
            ]
          },
          "tags": [
            "METADATA_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "6.json"
        },
        "model_output": {
          "favicons": [
            {
              "size": "180x180",
              "url": "/apple-touch-icon.png"
            },
            {
              "size": "32x32",
              "url": "/favicon-32x32.png"
            },
            {
              "size": "16x16",
              "url": "/favicon-16x16.png"
            }
          ]
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "7.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0000000715255737,
        "cost": 0.00011125,
        "usage": {
          "input_tokens": 260,
          "output_tokens": 37,
          "total_tokens": 297
        },
        "latency": 1.5625128746032715,
        "test_case": {
          "expected_output": {
            "title": "Example Domain",
            "num_links": 1,
            "num_paragraphs": 2
          },
          "input": {
            "input_file": "example.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON: \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"title\": \"string\",\n  \"num_links\": \"number\",\n  \"num_paragraphs\": \"number\"\n}",
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "7.json"
        },
        "model_output": {
          "title": "Example Domain",
          "num_links": 1,
          "num_paragraphs": 2
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "1.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999642372132,
        "cost": 0.0101625,
        "usage": {
          "input_tokens": 40470,
          "output_tokens": 36,
          "total_tokens": 40506
        },
        "latency": 7.545324087142944,
        "test_case": {
          "expected_output": {
            "insights": {
              "total_pageviews": 584,
              "total_visitors": 417
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into a JSON object:\n- Total pageviews\n- Total visitors\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"total_pageviews\": number,\n    \"total_visitors\": number\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "total_pageviews": 584,
            "total_visitors": 417
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "2.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.01019725,
        "usage": {
          "input_tokens": 40494,
          "output_tokens": 59,
          "total_tokens": 40553
        },
        "latency": 7.935103893280029,
        "test_case": {
          "expected_output": {
            "insights": {
              "referral_sources": {
                "direct": 240,
                "twitter.com": 68,
                "news.ycombinator.com": 41
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the top 3 referral sources from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the top 3 referral sources with their pageview counts into JSON.\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"referral_sources\": {\n      \"direct\": number,\n      \"twitter.com\": number,\n      \"news.ycombinator.com\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "referral_sources": {
              "direct": 240,
              "twitter.com": 68,
              "news.ycombinator.com": 41
            }
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "3.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999284744263,
        "cost": 0.01018225,
        "usage": {
          "input_tokens": 40474,
          "output_tokens": 51,
          "total_tokens": 40525
        },
        "latency": 10.504531145095825,
        "test_case": {
          "expected_output": {
            "insights": {
              "device_usage": {
                "mobile": 68,
                "desktop": 32,
                "tablet": 0.7
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract device usage percentages from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the percentage breakdown of device types used into JSON.\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"device_usage\": {\n      \"mobile\": number,\n      \"desktop\": number,\n      \"tablet\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "3.json"
        },
        "model_output": {
          "insights": {
            "device_usage": {
              "mobile": 68,
              "desktop": 32,
              "tablet": 0.7
            }
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "4.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9764013528823853,
        "cost": 0.026011,
        "usage": {
          "input_tokens": 103744,
          "output_tokens": 60,
          "total_tokens": 103804
        },
        "latency": 26.050978899002075,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic post information from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML content and extract the following basic post information into a JSON object. \n- Post title\n- Author name\n- Subreddit name\n- Post score\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"post_title\": string,\n \"author\": string,\n \"subreddit\": string,\n \"post_score\": string\n}",
          "expected_output": {
            "post_title": "Is there a simple way to monitor Bedrock Costs?",
            "author": "Bob321423",
            "subreddit": "r/aws",
            "post_score": "5"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "4.json"
        },
        "model_output": {
          "post_title": "Is there a simple way to monitor Bedrock Costs?",
          "author": "Bob321423",
          "subreddit": "aws",
          "post_score": "5"
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "5.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9782352328300477,
        "cost": 0.02602,
        "usage": {
          "input_tokens": 103755,
          "output_tokens": 65,
          "total_tokens": 103820
        },
        "latency": 26.024309873580933,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"community_name\": string,\n \"total_members\": number,\n \"active_members\": number,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "r/aws",
            "total_members": 316355,
            "active_members": 48,
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "5.json"
        },
        "model_output": {
          "community_name": "r/aws",
          "total_members": 316355,
          "active_members": 48,
          "created_date": "2008-01-26",
          "community_type": "Public"
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "1.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9820192575454711,
        "cost": 0.01022375,
        "usage": {
          "input_tokens": 40535,
          "output_tokens": 72,
          "total_tokens": 40607
        },
        "latency": 8.614076852798462,
        "test_case": {
          "expected_output": {
            "insights": {
              "top_page": {
                "url": "/blog/tone-evaluation",
                "pageviews": 296,
                "percentage_of_total": 50.5,
                "has_social_traffic": true
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze the most popular page's metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract information about the most visited page into JSON:\n- The page URL\n- Number of pageviews\n- Calculate what percentage of total pageviews this represents\n- Whether it received any social media traffic (from Twitter, Facebook, or LinkedIn)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"top_page\": {\n      \"url\": string,\n      \"pageviews\": number,\n      \"percentage_of_total\": number,\n      \"has_social_traffic\": boolean\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "top_page": {
              "url": "/blog/tone-evaluation",
              "pageviews": 296,
              "percentage_of_total": 50.68,
              "has_social_traffic": true
            }
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "2.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9888917207717896,
        "cost": 0.010211999999999999,
        "usage": {
          "input_tokens": 40518,
          "output_tokens": 66,
          "total_tokens": 40584
        },
        "latency": 8.29872465133667,
        "test_case": {
          "expected_output": {
            "insights": {
              "mobile_stats": {
                "percentage": 68,
                "dominant_browser": "iOS Safari",
                "browser_share": 48,
                "alignment_score": 0.71
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze mobile usage patterns from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract mobile usage patterns into JSON:\n- Mobile device usage percentage\n- Most used mobile browser\n- That browser's overall share percentage\n- Calculate an alignment score (browser_share/mobile_percentage)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"mobile_stats\": {\n      \"percentage\": number,\n      \"dominant_browser\": string,\n      \"browser_share\": number,\n      \"alignment_score\": number\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "mobile_stats": {
              "percentage": 68,
              "dominant_browser": "iOS Safari",
              "browser_share": 48,
              "alignment_score": 0.706
            }
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "3.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.933711564540863,
        "cost": 0.02610675,
        "usage": {
          "input_tokens": 103747,
          "output_tokens": 136,
          "total_tokens": 103883
        },
        "latency": 27.708436965942383,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "system_prompt": "You are a data extraction assistant. Analyze comment patterns and extract comment-related metrics from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following comment information into JSON:\n- Total number of comments\n- List of all comment authors\n- Timeline of comments (how long ago each was posted)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"total_comments\": number,\n \"comment_authors\": string[],\n \"comments_timeline\": string[]\n}",
          "expected_output": {
            "total_comments": 5,
            "comment_authors": [
              "Truelikegiroux",
              "TechMktr",
              "MrPebblesMeow",
              "AdRepulsive7837",
              "noydoc"
            ],
            "comments_timeline": [
              "5 months ago",
              "5 months ago",
              "4 months ago",
              "4 months ago",
              "2 months ago"
            ]
          },
          "difficulty": "medium",
          "test_id": "3.json"
        },
        "model_output": {
          "total_comments": 5,
          "comment_authors": [
            "Truelikegiroux",
            "TechMktr",
            "MrPebblesMeow",
            "AdRepulsive7837",
            "noydoc"
          ],
          "comments_timeline": [
            "5 mo. ago",
            "5 mo. ago",
            "4 mo. ago",
            "4 mo. ago",
            "2 mo. ago"
          ]
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "4.json",
        "difficulty": "medium",
        "tags": [
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9688437819480896,
        "cost": 0.02602125,
        "usage": {
          "input_tokens": 103755,
          "output_tokens": 66,
          "total_tokens": 103821
        },
        "latency": 26.158315181732178,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"community_name\": string,\n \"total_members\": string,\n \"active_members\": string,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "aws",
            "total_members": "316355",
            "active_members": "48",
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "4.json"
        },
        "model_output": {
          "community_name": "r/aws",
          "total_members": "316K",
          "active_members": "48",
          "created_date": "Jan 26, 2008",
          "community_type": "Public"
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "5.json",
        "difficulty": "medium",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0028380000000000002,
        "usage": {
          "input_tokens": 10687,
          "output_tokens": 133,
          "total_tokens": 10820
        },
        "latency": 4.208698034286499,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the main logo SVG content and properties from the provided webpage HTML.",
          "user_prompt": "Please extract the main navigation logo SVG element, including its viewBox, dimensions, and path data. Don't deconstruct the paths. Store them as strings wtih the tag inside. \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"logo\": {\n   \"viewBox\": string,\n   \"width\": string,\n   \"height\": string,\n   \"paths\": string[]\n }\n}",
          "expected_output": {
            "logo": {
              "viewBox": "0 0 100 100",
              "width": "30px",
              "height": "30px",
              "paths": [
                "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
                "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
                "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "5.json"
        },
        "model_output": {
          "logo": {
            "viewBox": "0 0 100 100",
            "width": "30px",
            "height": "30px",
            "paths": [
              "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
              "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
              "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
            ]
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "1.json",
        "difficulty": "hard",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "METADATA_EXTRACTION",
          "STRUCTURAL_EXTRACTION"
        ],
        "score": 0.9391164660453797,
        "cost": 0.010232499999999999,
        "usage": {
          "input_tokens": 40530,
          "output_tokens": 80,
          "total_tokens": 40610
        },
        "latency": 8.36795687675476,
        "test_case": {
          "expected_output": {
            "insights": {
              "most_popular_page": "/blog/tone-evaluation",
              "most_popular_referral_source": "twitter.com",
              "dominant_device_type": "Mobile",
              "dominant_browser": "iOS Safari",
              "dominant_country": "United States"
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract key analytics insights from the provided webpage HTML and format them according to the specified schema.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following analytics insights into a JSON object:\n- Most visited page\n- Top referral source\n- Most common device type\n- Most used browser\n- Country with highest traffic\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"most_popular_page\": string,\n    \"most_popular_referral_source\": string,\n    \"dominant_device_type\": string,\n    \"dominant_browser\": string,\n    \"dominant_country\": string\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION",
            "METADATA_EXTRACTION",
            "STRUCTURAL_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "most_popular_page": "/blog/tone-evaluation",
            "most_popular_referral_source": "(direct)",
            "dominant_device_type": "mobile",
            "dominant_browser": "iOS Safari",
            "dominant_country": "United States"
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "2.json",
        "difficulty": "hard",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION"
        ],
        "score": 0.9999999642372132,
        "cost": 0.026494,
        "usage": {
          "input_tokens": 103781,
          "output_tokens": 439,
          "total_tokens": 104220
        },
        "latency": 32.236327171325684,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and organize the complete navigation structure and resource links from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following navigation structure into JSON:\n- Main resource links with their titles and URLs\n- Policy links with their titles and URLs\n- All sidebar resource links\n\nOrganize the information hierarchically\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"resources\": {\n   \"main_links\": [{ \"title\": string, \"url\": string }],\n   \"policies\": [{ \"title\": string, \"url\": string }],\n   \"sidebar_resources\": string[]\n }\n}",
          "expected_output": {
            "resources": {
              "main_links": [
                {
                  "title": "About Reddit",
                  "url": "https://www.redditinc.com"
                },
                {
                  "title": "Advertise",
                  "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
                },
                {
                  "title": "Help",
                  "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
                },
                {
                  "title": "Blog",
                  "url": "https://redditblog.com/"
                },
                {
                  "title": "Careers",
                  "url": "https://www.redditinc.com/careers"
                },
                {
                  "title": "Press",
                  "url": "https://www.redditinc.com/press"
                }
              ],
              "policies": [
                {
                  "title": "Content Policy",
                  "url": "https://www.redditinc.com/policies/content-policy"
                },
                {
                  "title": "Privacy Policy",
                  "url": "https://www.reddit.com/policies/privacy-policy"
                },
                {
                  "title": "User Agreement",
                  "url": "https://www.redditinc.com/policies/user-agreement"
                }
              ],
              "sidebar_resources": [
                "Amazon Web Services blog",
                "AWS status page",
                "AWS documentation",
                "AWS YouTube channel",
                "AWS Samples on GitHub",
                "AWS Labs on GitHub",
                "AWS General Reference",
                "High Scalability",
                "re:Invent Videos",
                "Workshops",
                "AWS Geek: Cloud Diagrams",
                "AWS Stash",
                "AWS Architecture Center",
                "AWS re:Post"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "2.json"
        },
        "model_output": {
          "resources": {
            "main_links": [
              {
                "title": "About Reddit",
                "url": "https://www.redditinc.com"
              },
              {
                "title": "Advertise",
                "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
              },
              {
                "title": "Help",
                "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
              },
              {
                "title": "Blog",
                "url": "https://redditblog.com/"
              },
              {
                "title": "Careers",
                "url": "https://www.redditinc.com/careers"
              },
              {
                "title": "Press",
                "url": "https://www.redditinc.com/press"
              }
            ],
            "policies": [
              {
                "title": "Content Policy",
                "url": "https://www.redditinc.com/policies/content-policy"
              },
              {
                "title": "Privacy Policy",
                "url": "https://www.reddit.com/policies/privacy-policy"
              },
              {
                "title": "User Agreement",
                "url": "https://www.redditinc.com/policies/user-agreement"
              }
            ],
            "sidebar_resources": [
              "Amazon Web Services blog",
              "AWS status page",
              "AWS documentation",
              "AWS YouTube channel",
              "AWS Samples on GitHub",
              "AWS Labs on GitHub",
              "AWS General Reference",
              "High Scalability",
              "re:Invent Videos",
              "Workshops",
              "AWS Geek: Cloud Diagrams",
              "AWS Stash",
              "AWS Architecture Center",
              "AWS re:Post"
            ]
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "test_id": "3.json",
        "difficulty": "hard",
        "tags": [
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0026795,
        "usage": {
          "input_tokens": 10643,
          "output_tokens": 15,
          "total_tokens": 10658
        },
        "latency": 3.11403489112854,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and decode any base64 encoded logo images from the provided webpage HTML.",
          "user_prompt": "Please analyze the HTML for any base64 encoded logo images. Extract the base64 encoded string or return empty string \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"encodedImage\": string\n}",
          "expected_output": {
            "encodedImage": ""
          },
          "tags": [
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "3.json"
        },
        "model_output": {
          "encodedImage": ""
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "6.json",
        "difficulty": "easy",
        "tags": [
          "METADATA_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.033588,
        "usage": {
          "input_tokens": 10661,
          "output_tokens": 107,
          "total_tokens": 10768
        },
        "latency": 4.471398115158081,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract favicon URLs from the provided webpage HTML.",
          "user_prompt": "Please extract all favicon URLs from the HTML head section. Include any favicon references with different sizes. Format the output as a JSON array of objects with size and URL properties.\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"favicons\": [{\n   \"size\": string,\n   \"url\": string\n }]\n}",
          "expected_output": {
            "favicons": [
              {
                "size": "180x180",
                "url": "/apple-touch-icon.png"
              },
              {
                "size": "32x32",
                "url": "/favicon-32x32.png"
              },
              {
                "size": "16x16",
                "url": "/favicon-16x16.png"
              }
            ]
          },
          "tags": [
            "METADATA_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "6.json"
        },
        "model_output": {
          "favicons": [
            {
              "size": "180x180",
              "url": "/apple-touch-icon.png"
            },
            {
              "size": "32x32",
              "url": "/favicon-32x32.png"
            },
            {
              "size": "16x16",
              "url": "/favicon-16x16.png"
            }
          ]
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "7.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0000000715255737,
        "cost": 0.00132,
        "usage": {
          "input_tokens": 260,
          "output_tokens": 36,
          "total_tokens": 296
        },
        "latency": 1.6938209533691406,
        "test_case": {
          "expected_output": {
            "title": "Example Domain",
            "num_links": 1,
            "num_paragraphs": 2
          },
          "input": {
            "input_file": "example.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON: \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"title\": \"string\",\n  \"num_links\": \"number\",\n  \"num_paragraphs\": \"number\"\n}",
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "7.json"
        },
        "model_output": {
          "title": "Example Domain",
          "num_links": 1,
          "num_paragraphs": 2
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "1.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999642372132,
        "cost": 0.12194999999999999,
        "usage": {
          "input_tokens": 40470,
          "output_tokens": 36,
          "total_tokens": 40506
        },
        "latency": 6.797911643981934,
        "test_case": {
          "expected_output": {
            "insights": {
              "total_pageviews": 584,
              "total_visitors": 417
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into a JSON object:\n- Total pageviews\n- Total visitors\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"total_pageviews\": number,\n    \"total_visitors\": number\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "total_pageviews": 584,
            "total_visitors": 417
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "2.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.122367,
        "usage": {
          "input_tokens": 40494,
          "output_tokens": 59,
          "total_tokens": 40553
        },
        "latency": 5.289535045623779,
        "test_case": {
          "expected_output": {
            "insights": {
              "referral_sources": {
                "direct": 240,
                "twitter.com": 68,
                "news.ycombinator.com": 41
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the top 3 referral sources from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the top 3 referral sources with their pageview counts into JSON.\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"referral_sources\": {\n      \"direct\": number,\n      \"twitter.com\": number,\n      \"news.ycombinator.com\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "referral_sources": {
              "direct": 240,
              "twitter.com": 68,
              "news.ycombinator.com": 41
            }
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "3.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999284744263,
        "cost": 0.122187,
        "usage": {
          "input_tokens": 40474,
          "output_tokens": 51,
          "total_tokens": 40525
        },
        "latency": 7.138214826583862,
        "test_case": {
          "expected_output": {
            "insights": {
              "device_usage": {
                "mobile": 68,
                "desktop": 32,
                "tablet": 0.7
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract device usage percentages from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the percentage breakdown of device types used into JSON.\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"device_usage\": {\n      \"mobile\": number,\n      \"desktop\": number,\n      \"tablet\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "3.json"
        },
        "model_output": {
          "insights": {
            "device_usage": {
              "mobile": 68,
              "desktop": 32,
              "tablet": 0.7
            }
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "4.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9764013528823853,
        "cost": 0.312102,
        "usage": {
          "input_tokens": 103744,
          "output_tokens": 58,
          "total_tokens": 103802
        },
        "latency": 14.88117504119873,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic post information from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML content and extract the following basic post information into a JSON object. \n- Post title\n- Author name\n- Subreddit name\n- Post score\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"post_title\": string,\n \"author\": string,\n \"subreddit\": string,\n \"post_score\": string\n}",
          "expected_output": {
            "post_title": "Is there a simple way to monitor Bedrock Costs?",
            "author": "Bob321423",
            "subreddit": "r/aws",
            "post_score": "5"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "4.json"
        },
        "model_output": {
          "post_title": "Is there a simple way to monitor Bedrock Costs?",
          "author": "Bob321423",
          "subreddit": "aws",
          "post_score": "5"
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "5.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.13599487245082856,
        "cost": 0.312525,
        "usage": {
          "input_tokens": 103755,
          "output_tokens": 84,
          "total_tokens": 103839
        },
        "latency": 16.507007122039795,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"community_name\": string,\n \"total_members\": number,\n \"active_members\": number,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "r/aws",
            "total_members": 316355,
            "active_members": 48,
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "5.json"
        },
        "model_output": {
          "text": "Here's the extracted community information in JSON format:\n\n{\n  \"community_name\": \"r/aws\",\n  \"total_members\": 316355,\n  \"active_members\": 48,\n  \"created_date\": \"2008-01-26T01:09:36.945Z\",\n  \"community_type\": \"public\"\n}"
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "1.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9912243127822876,
        "cost": 0.122685,
        "usage": {
          "input_tokens": 40535,
          "output_tokens": 72,
          "total_tokens": 40607
        },
        "latency": 8.162566900253296,
        "test_case": {
          "expected_output": {
            "insights": {
              "top_page": {
                "url": "/blog/tone-evaluation",
                "pageviews": 296,
                "percentage_of_total": 50.5,
                "has_social_traffic": true
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze the most popular page's metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract information about the most visited page into JSON:\n- The page URL\n- Number of pageviews\n- Calculate what percentage of total pageviews this represents\n- Whether it received any social media traffic (from Twitter, Facebook, or LinkedIn)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"top_page\": {\n      \"url\": string,\n      \"pageviews\": number,\n      \"percentage_of_total\": number,\n      \"has_social_traffic\": boolean\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "top_page": {
              "url": "/blog/tone-evaluation",
              "pageviews": 296,
              "percentage_of_total": 50.7,
              "has_social_traffic": true
            }
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "2.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9776516556739807,
        "cost": 0.12261899999999999,
        "usage": {
          "input_tokens": 40518,
          "output_tokens": 71,
          "total_tokens": 40589
        },
        "latency": 7.2469189167022705,
        "test_case": {
          "expected_output": {
            "insights": {
              "mobile_stats": {
                "percentage": 68,
                "dominant_browser": "iOS Safari",
                "browser_share": 48,
                "alignment_score": 0.71
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze mobile usage patterns from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract mobile usage patterns into JSON:\n- Mobile device usage percentage\n- Most used mobile browser\n- That browser's overall share percentage\n- Calculate an alignment score (browser_share/mobile_percentage)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"mobile_stats\": {\n      \"percentage\": number,\n      \"dominant_browser\": string,\n      \"browser_share\": number,\n      \"alignment_score\": number\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "mobile_stats": {
              "percentage": 68,
              "dominant_browser": "iOS Safari",
              "browser_share": 48,
              "alignment_score": 0.7058823529411765
            }
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "3.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.10077833533287048,
        "cost": 0.313371,
        "usage": {
          "input_tokens": 103747,
          "output_tokens": 142,
          "total_tokens": 103889
        },
        "latency": 18.205872058868408,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "system_prompt": "You are a data extraction assistant. Analyze comment patterns and extract comment-related metrics from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following comment information into JSON:\n- Total number of comments\n- List of all comment authors\n- Timeline of comments (how long ago each was posted)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"total_comments\": number,\n \"comment_authors\": string[],\n \"comments_timeline\": string[]\n}",
          "expected_output": {
            "total_comments": 5,
            "comment_authors": [
              "Truelikegiroux",
              "TechMktr",
              "MrPebblesMeow",
              "AdRepulsive7837",
              "noydoc"
            ],
            "comments_timeline": [
              "5 months ago",
              "5 months ago",
              "4 months ago",
              "4 months ago",
              "2 months ago"
            ]
          },
          "difficulty": "medium",
          "test_id": "3.json"
        },
        "model_output": {
          "text": "Here's the extracted comment information in the requested JSON format:\n\n{\n    \"total_comments\": 5,\n    \"comment_authors\": [\n        \"Truelikegiroux\",\n        \"TechMktr\", \n        \"MrPebblesMeow\",\n        \"AdRepulsive7837\",\n        \"noydoc\"\n    ],\n    \"comments_timeline\": [\n        \"5 months ago\",\n        \"5 months ago\",\n        \"4 months ago\",\n        \"4 months ago\", \n        \"2 months ago\"\n    ]\n}"
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "4.json",
        "difficulty": "medium",
        "tags": [
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.1231178730726242,
        "cost": 0.31242000000000003,
        "usage": {
          "input_tokens": 103755,
          "output_tokens": 77,
          "total_tokens": 103832
        },
        "latency": 17.07974600791931,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"community_name\": string,\n \"total_members\": string,\n \"active_members\": string,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "aws",
            "total_members": "316355",
            "active_members": "48",
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "4.json"
        },
        "model_output": {
          "text": "Here's the extracted community information in JSON format:\n\n{\n \"community_name\": \"r/aws\",\n \"total_members\": \"316,355\",\n \"active_members\": \"48\",\n \"created_date\": \"Jan 26, 2008\",\n \"community_type\": \"Public\"\n}"
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "5.json",
        "difficulty": "medium",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 0.9401014089584351,
        "cost": 0.033965999999999996,
        "usage": {
          "input_tokens": 10687,
          "output_tokens": 127,
          "total_tokens": 10814
        },
        "latency": 4.79291296005249,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the main logo SVG content and properties from the provided webpage HTML.",
          "user_prompt": "Please extract the main navigation logo SVG element, including its viewBox, dimensions, and path data. Don't deconstruct the paths. Store them as strings wtih the tag inside. \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"logo\": {\n   \"viewBox\": string,\n   \"width\": string,\n   \"height\": string,\n   \"paths\": string[]\n }\n}",
          "expected_output": {
            "logo": {
              "viewBox": "0 0 100 100",
              "width": "30px",
              "height": "30px",
              "paths": [
                "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
                "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
                "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "5.json"
        },
        "model_output": {
          "logo": {
            "viewBox": "0 0 100 100",
            "width": "30",
            "height": "30",
            "paths": [
              "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
              "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
              "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
            ]
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "1.json",
        "difficulty": "hard",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "METADATA_EXTRACTION",
          "STRUCTURAL_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.12281999999999998,
        "usage": {
          "input_tokens": 40530,
          "output_tokens": 82,
          "total_tokens": 40612
        },
        "latency": 8.139259099960327,
        "test_case": {
          "expected_output": {
            "insights": {
              "most_popular_page": "/blog/tone-evaluation",
              "most_popular_referral_source": "twitter.com",
              "dominant_device_type": "Mobile",
              "dominant_browser": "iOS Safari",
              "dominant_country": "United States"
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract key analytics insights from the provided webpage HTML and format them according to the specified schema.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following analytics insights into a JSON object:\n- Most visited page\n- Top referral source\n- Most common device type\n- Most used browser\n- Country with highest traffic\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"most_popular_page\": string,\n    \"most_popular_referral_source\": string,\n    \"dominant_device_type\": string,\n    \"dominant_browser\": string,\n    \"dominant_country\": string\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION",
            "METADATA_EXTRACTION",
            "STRUCTURAL_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "most_popular_page": "/blog/tone-evaluation",
            "most_popular_referral_source": "twitter.com",
            "dominant_device_type": "mobile",
            "dominant_browser": "iOS Safari",
            "dominant_country": "United States"
          }
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "2.json",
        "difficulty": "hard",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION"
        ],
        "score": 0.21963239908218382,
        "cost": 0.320778,
        "usage": {
          "input_tokens": 103781,
          "output_tokens": 629,
          "total_tokens": 104410
        },
        "latency": 22.614398956298828,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and organize the complete navigation structure and resource links from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following navigation structure into JSON:\n- Main resource links with their titles and URLs\n- Policy links with their titles and URLs\n- All sidebar resource links\n\nOrganize the information hierarchically\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"resources\": {\n   \"main_links\": [{ \"title\": string, \"url\": string }],\n   \"policies\": [{ \"title\": string, \"url\": string }],\n   \"sidebar_resources\": string[]\n }\n}",
          "expected_output": {
            "resources": {
              "main_links": [
                {
                  "title": "About Reddit",
                  "url": "https://www.redditinc.com"
                },
                {
                  "title": "Advertise",
                  "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
                },
                {
                  "title": "Help",
                  "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
                },
                {
                  "title": "Blog",
                  "url": "https://redditblog.com/"
                },
                {
                  "title": "Careers",
                  "url": "https://www.redditinc.com/careers"
                },
                {
                  "title": "Press",
                  "url": "https://www.redditinc.com/press"
                }
              ],
              "policies": [
                {
                  "title": "Content Policy",
                  "url": "https://www.redditinc.com/policies/content-policy"
                },
                {
                  "title": "Privacy Policy",
                  "url": "https://www.reddit.com/policies/privacy-policy"
                },
                {
                  "title": "User Agreement",
                  "url": "https://www.redditinc.com/policies/user-agreement"
                }
              ],
              "sidebar_resources": [
                "Amazon Web Services blog",
                "AWS status page",
                "AWS documentation",
                "AWS YouTube channel",
                "AWS Samples on GitHub",
                "AWS Labs on GitHub",
                "AWS General Reference",
                "High Scalability",
                "re:Invent Videos",
                "Workshops",
                "AWS Geek: Cloud Diagrams",
                "AWS Stash",
                "AWS Architecture Center",
                "AWS re:Post"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "2.json"
        },
        "model_output": {
          "text": "Here's the extracted navigation structure in JSON format:\n\n{\n  \"resources\": {\n    \"main_links\": [\n      {\"title\": \"Amazon Web Services blog\", \"url\": \"https://aws.amazon.com/blogs/aws/\"},\n      {\"title\": \"AWS status page\", \"url\": \"http://status.aws.amazon.com/\"},\n      {\"title\": \"AWS documentation\", \"url\": \"http://aws.amazon.com/documentation/\"},\n      {\"title\": \"AWS YouTube channel\", \"url\": \"https://www.youtube.com/user/AmazonWebServices/\"},\n      {\"title\": \"AWS Samples on GitHub\", \"url\": \"https://github.com/aws-samples\"},\n      {\"title\": \"AWS Labs on GitHub\", \"url\": \"https://github.com/awslabs\"},\n      {\"title\": \"AWS General Reference\", \"url\": \"https://docs.aws.amazon.com/general/latest/gr/Welcome.html\"},\n      {\"title\": \"High Scalability\", \"url\": \"http://www.highscalability.com/\"},\n      {\"title\": \"re:Invent Videos\", \"url\": \"https://reinventvideos.com/\"},\n      {\"title\": \"Workshops\", \"url\": \"https://workshops.aws/\"},\n      {\"title\": \"AWS Geek: Cloud Diagrams\", \"url\": \"https://www.awsgeek.com/\"},\n      {\"title\": \"AWS Stash\", \"url\": \"https://awsstash.com/\"},\n      {\"title\": \"AWS Architecture Center\", \"url\": \"https://aws.amazon.com/architecture/\"},\n      {\"title\": \"AWS re:Post\", \"url\": \"https://repost.aws/\"}\n    ],\n    \"policies\": [\n      {\"title\": \"Content Policy\", \"url\": \"https://www.redditinc.com/policies/content-policy\"},\n      {\"title\": \"Privacy Policy\", \"url\": \"https://www.reddit.com/policies/privacy-policy\"},\n      {\"title\": \"User Agreement\", \"url\": \"https://www.redditinc.com/policies/user-agreement\"}\n    ],\n    \"sidebar_resources\": [\n      \"/r/AWScertifications\",\n      \"/r/virtualization\", \n      \"/r/devops\",\n      \"/r/kubernetes\",\n      \"/r/terraform\",\n      \"/r/cloudcomputing\",\n      \"/r/bigdata\",\n      \"/r/vmware\",\n      \"/r/networking\",\n      \"/r/sysadmin\",\n      \"/r/netsec\",\n      \"/r/aws_cdk\",\n      \"/r/AWSCloudFormation\"\n    ]\n  }\n}"
        }
      },
      {
        "model": "arn:aws:bedrock:us-east-1:502675305491:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "test_id": "3.json",
        "difficulty": "hard",
        "tags": [
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.032139,
        "usage": {
          "input_tokens": 10643,
          "output_tokens": 14,
          "total_tokens": 10657
        },
        "latency": 2.647732973098755,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and decode any base64 encoded logo images from the provided webpage HTML.",
          "user_prompt": "Please analyze the HTML for any base64 encoded logo images. Extract the base64 encoded string or return empty string \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"encodedImage\": string\n}",
          "expected_output": {
            "encodedImage": ""
          },
          "tags": [
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "3.json"
        },
        "model_output": {
          "encodedImage": ""
        }
      },
      
      {
        "model": "command-r",
        "test_id": "3.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999284744263,
        "cost": 0.0070608,
        "usage": {
          "input_tokens": 46900.0,
          "output_tokens": 43.0,
          "total_tokens": 46943.0
        },
        "latency": 5.742077827453613,
        "test_case": {
          "expected_output": {
            "insights": {
              "device_usage": {
                "mobile": 68,
                "desktop": 32,
                "tablet": 0.7
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract device usage percentages from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the percentage breakdown of device types used into JSON.\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"device_usage\": {\n      \"mobile\": number,\n      \"desktop\": number,\n      \"tablet\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "3.json"
        },
        "model_output": {
          "insights": {
            "device_usage": {
              "mobile": 68,
              "desktop": 32,
              "tablet": 0.7
            }
          }
        }
      },
      {
        "model": "command-r",
        "test_id": "4.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.8928160309791565,
        "cost": 0.016022099999999997,
        "usage": {
          "input_tokens": 106622.0,
          "output_tokens": 48.0,
          "total_tokens": 106670.0
        },
        "latency": 16.689614057540894,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic post information from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML content and extract the following basic post information into a JSON object. \n- Post title\n- Author name\n- Subreddit name\n- Post score\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"post_title\": string,\n \"author\": string,\n \"subreddit\": string,\n \"post_score\": string\n}",
          "expected_output": {
            "post_title": "Is there a simple way to monitor Bedrock Costs?",
            "author": "Bob321423",
            "subreddit": "r/aws",
            "post_score": "5"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "4.json"
        },
        "model_output": {
          "post_title": "Is there a simple way to monitor Bedrock Costs?",
          "author": "peytoncasper",
          "subreddit": "aws",
          "post_score": "5"
        }
      },
      {
        "model": "command-r",
        "test_id": "5.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9782352328300477,
        "cost": 0.01603425,
        "usage": {
          "input_tokens": 106635.0,
          "output_tokens": 65.0,
          "total_tokens": 106700.0
        },
        "latency": 20.320124864578247,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"community_name\": string,\n \"total_members\": number,\n \"active_members\": number,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "r/aws",
            "total_members": 316355,
            "active_members": 48,
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "5.json"
        },
        "model_output": {
          "community_name": "r/aws",
          "total_members": 316355,
          "active_members": 48,
          "created_date": "2008-01-26",
          "community_type": "public"
        }
      },
      {
        "model": "command-r",
        "test_id": "1.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.8654138684272766,
        "cost": 0.007080749999999999,
        "usage": {
          "input_tokens": 46957.0,
          "output_tokens": 62.0,
          "total_tokens": 47019.0
        },
        "latency": 7.596395015716553,
        "test_case": {
          "expected_output": {
            "insights": {
              "top_page": {
                "url": "/blog/tone-evaluation",
                "pageviews": 296,
                "percentage_of_total": 50.5,
                "has_social_traffic": true
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze the most popular page's metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract information about the most visited page into JSON:\n- The page URL\n- Number of pageviews\n- Calculate what percentage of total pageviews this represents\n- Whether it received any social media traffic (from Twitter, Facebook, or LinkedIn)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"top_page\": {\n      \"url\": string,\n      \"pageviews\": number,\n      \"percentage_of_total\": number,\n      \"has_social_traffic\": boolean\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "top_page": {
              "url": "/peytoncasper.com",
              "pageviews": 296,
              "percentage_of_total": 50,
              "has_social_traffic": true
            }
          }
        }
      },
      {
        "model": "command-r",
        "test_id": "2.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9888917207717896,
        "cost": 0.007076849999999999,
        "usage": {
          "input_tokens": 46943.0,
          "output_tokens": 59.0,
          "total_tokens": 47002.0
        },
        "latency": 7.42326283454895,
        "test_case": {
          "expected_output": {
            "insights": {
              "mobile_stats": {
                "percentage": 68,
                "dominant_browser": "iOS Safari",
                "browser_share": 48,
                "alignment_score": 0.71
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze mobile usage patterns from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract mobile usage patterns into JSON:\n- Mobile device usage percentage\n- Most used mobile browser\n- That browser's overall share percentage\n- Calculate an alignment score (browser_share/mobile_percentage)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"mobile_stats\": {\n      \"percentage\": number,\n      \"dominant_browser\": string,\n      \"browser_share\": number,\n      \"alignment_score\": number\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "mobile_stats": {
              "percentage": 68,
              "dominant_browser": "iOS Safari",
              "browser_share": 48,
              "alignment_score": 0.706
            }
          }
        }
      },
      {
        "model": "command-r",
        "test_id": "3.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9990242838859558,
        "cost": 0.016046249999999998,
        "usage": {
          "input_tokens": 106627.0,
          "output_tokens": 87.0,
          "total_tokens": 106714.0
        },
        "latency": 24.37242078781128,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "system_prompt": "You are a data extraction assistant. Analyze comment patterns and extract comment-related metrics from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following comment information into JSON:\n- Total number of comments\n- List of all comment authors\n- Timeline of comments (how long ago each was posted)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"total_comments\": number,\n \"comment_authors\": string[],\n \"comments_timeline\": string[]\n}",
          "expected_output": {
            "total_comments": 5,
            "comment_authors": [
              "Truelikegiroux",
              "TechMktr",
              "MrPebblesMeow",
              "AdRepulsive7837",
              "noydoc"
            ],
            "comments_timeline": [
              "5 months ago",
              "5 months ago",
              "4 months ago",
              "4 months ago",
              "2 months ago"
            ]
          },
          "difficulty": "medium",
          "test_id": "3.json"
        },
        "model_output": {
          "total_comments": 5,
          "comment_authors": [
            "Truelikegiroux",
            "TechMktr",
            "MrPebblesMeow",
            "AdRepulsive7837",
            "noydoc"
          ],
          "comments_timeline": [
            "5 months ago",
            "5 months ago",
            "4 months ago",
            "3 months ago",
            "2 months ago"
          ]
        }
      },
      {
        "model": "command-r",
        "test_id": "4.json",
        "difficulty": "medium",
        "tags": [
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "error": "Expecting property name enclosed in double quotes: line 2 column 1 (char 2)",
        "score": 0.0,
        "cost": 0.0,
        "usage": {
          "input_tokens": 0,
          "output_tokens": 0
        },
        "latency": 18.6950101852417,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"community_name\": string,\n \"total_members\": string,\n \"active_members\": string,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "aws",
            "total_members": "316355",
            "active_members": "48",
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "4.json"
        },
        "model_output": null
      },
      {
        "model": "command-r",
        "test_id": "5.json",
        "difficulty": "medium",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 0.9950521111488342,
        "cost": 0.0019408499999999998,
        "usage": {
          "input_tokens": 12427.0,
          "output_tokens": 128.0,
          "total_tokens": 12555.0
        },
        "latency": 2.991886854171753,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the main logo SVG content and properties from the provided webpage HTML.",
          "user_prompt": "Please extract the main navigation logo SVG element, including its viewBox, dimensions, and path data. Don't deconstruct the paths. Store them as strings wtih the tag inside. \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"logo\": {\n   \"viewBox\": string,\n   \"width\": string,\n   \"height\": string,\n   \"paths\": string[]\n }\n}",
          "expected_output": {
            "logo": {
              "viewBox": "0 0 100 100",
              "width": "30px",
              "height": "30px",
              "paths": [
                "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
                "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
                "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "5.json"
        },
        "model_output": {
          "logo": {
            "viewBox": "0 0 100 100",
            "width": "30px",
            "height": "30px",
            "paths": [
              "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"/>",
              "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"/>",
              "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"/>"
            ]
          }
        }
      },
      {
        "model": "command-r",
        "test_id": "1.json",
        "difficulty": "hard",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "METADATA_EXTRACTION",
          "STRUCTURAL_EXTRACTION"
        ],
        "score": 0.9864452600479126,
        "cost": 0.007085999999999999,
        "usage": {
          "input_tokens": 46956.0,
          "output_tokens": 71.0,
          "total_tokens": 47027.0
        },
        "latency": 7.4619300365448,
        "test_case": {
          "expected_output": {
            "insights": {
              "most_popular_page": "/blog/tone-evaluation",
              "most_popular_referral_source": "twitter.com",
              "dominant_device_type": "Mobile",
              "dominant_browser": "iOS Safari",
              "dominant_country": "United States"
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract key analytics insights from the provided webpage HTML and format them according to the specified schema.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following analytics insights into a JSON object:\n- Most visited page\n- Top referral source\n- Most common device type\n- Most used browser\n- Country with highest traffic\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"most_popular_page\": string,\n    \"most_popular_referral_source\": string,\n    \"dominant_device_type\": string,\n    \"dominant_browser\": string,\n    \"dominant_country\": string\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION",
            "METADATA_EXTRACTION",
            "STRUCTURAL_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "most_popular_page": "/blog/tone-evaluation",
            "most_popular_referral_source": "twitter.com",
            "dominant_device_type": "Mobile",
            "dominant_browser": "iOS Safari",
            "dominant_country": "US"
          }
        }
      },
      {
        "model": "command-r",
        "test_id": "2.json",
        "difficulty": "hard",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION"
        ],
        "score": 0.9057788559368678,
        "cost": 0.0163113,
        "usage": {
          "input_tokens": 106658.0,
          "output_tokens": 521.0,
          "total_tokens": 107179.0
        },
        "latency": 81.55019807815552,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and organize the complete navigation structure and resource links from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following navigation structure into JSON:\n- Main resource links with their titles and URLs\n- Policy links with their titles and URLs\n- All sidebar resource links\n\nOrganize the information hierarchically\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"resources\": {\n   \"main_links\": [{ \"title\": string, \"url\": string }],\n   \"policies\": [{ \"title\": string, \"url\": string }],\n   \"sidebar_resources\": string[]\n }\n}",
          "expected_output": {
            "resources": {
              "main_links": [
                {
                  "title": "About Reddit",
                  "url": "https://www.redditinc.com"
                },
                {
                  "title": "Advertise",
                  "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
                },
                {
                  "title": "Help",
                  "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
                },
                {
                  "title": "Blog",
                  "url": "https://redditblog.com/"
                },
                {
                  "title": "Careers",
                  "url": "https://www.redditinc.com/careers"
                },
                {
                  "title": "Press",
                  "url": "https://www.redditinc.com/press"
                }
              ],
              "policies": [
                {
                  "title": "Content Policy",
                  "url": "https://www.redditinc.com/policies/content-policy"
                },
                {
                  "title": "Privacy Policy",
                  "url": "https://www.reddit.com/policies/privacy-policy"
                },
                {
                  "title": "User Agreement",
                  "url": "https://www.redditinc.com/policies/user-agreement"
                }
              ],
              "sidebar_resources": [
                "Amazon Web Services blog",
                "AWS status page",
                "AWS documentation",
                "AWS YouTube channel",
                "AWS Samples on GitHub",
                "AWS Labs on GitHub",
                "AWS General Reference",
                "High Scalability",
                "re:Invent Videos",
                "Workshops",
                "AWS Geek: Cloud Diagrams",
                "AWS Stash",
                "AWS Architecture Center",
                "AWS re:Post"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "2.json"
        },
        "model_output": {
          "resources": {
            "main_links": [
              {
                "title": "About Reddit",
                "url": "https://www.redditinc.com"
              },
              {
                "title": "Advertise",
                "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
              },
              {
                "title": "Help",
                "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
              },
              {
                "title": "Blog",
                "url": "https://redditblog.com/"
              },
              {
                "title": "Careers",
                "url": "https://www.redditinc.com/careers"
              },
              {
                "title": "Press",
                "url": "https://www.redditinc.com/press"
              },
              {
                "title": "Communities",
                "url": "https://www.reddit.com/best/communities/1/"
              },
              {
                "title": "Best of Reddit",
                "url": "https://www.reddit.com/posts/2024/global/"
              },
              {
                "title": "Topics",
                "url": "https://www.reddit.com/topics/a-1/"
              }
            ],
            "policies": [
              {
                "title": "Content Policy",
                "url": "https://www.redditinc.com/policies/content-policy"
              },
              {
                "title": "Privacy Policy",
                "url": "https://www.reddit.com/policies/privacy-policy"
              },
              {
                "title": "User Agreement",
                "url": "https://www.redditinc.com/policies/user-agreement"
              }
            ],
            "sidebar_resources": [
              "Amazon Web Services blog",
              "AWS status page",
              "AWS documentation",
              "AWS YouTube channel",
              "AWS Samples on GitHub",
              "AWS Labs on GitHub",
              "AWS General Reference",
              "High Scalability",
              "re:Invent Videos",
              "Workshops",
              "AWS Geek: Cloud Diagrams",
              "AWS Stash",
              "AWS Architecture Center",
              "AWS re:Post"
            ]
          }
        }
      },
      {
        "model": "command-r",
        "test_id": "3.json",
        "difficulty": "hard",
        "tags": [
          "MEDIA_EXTRACTION"
        ],
        "error": "No valid JSON found in response",
        "score": 0.0,
        "cost": 0.0,
        "usage": {
          "input_tokens": 0,
          "output_tokens": 0
        },
        "latency": 17.840527772903442,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and decode any base64 encoded logo images from the provided webpage HTML.",
          "user_prompt": "Please analyze the HTML for any base64 encoded logo images. Extract the base64 encoded string or return empty string \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"encodedImage\": string\n}",
          "expected_output": {
            "encodedImage": ""
          },
          "tags": [
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "3.json"
        },
        "model_output": null
      },
      {
        "model": "command-r-plus",
        "test_id": "6.json",
        "difficulty": "easy",
        "tags": [
          "METADATA_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.032034999999999994,
        "usage": {
          "input_tokens": 12410.0,
          "output_tokens": 101.0,
          "total_tokens": 12511.0
        },
        "latency": 4.4772748947143555,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract favicon URLs from the provided webpage HTML.",
          "user_prompt": "Please extract all favicon URLs from the HTML head section. Include any favicon references with different sizes. Format the output as a JSON array of objects with size and URL properties.\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"favicons\": [{\n   \"size\": string,\n   \"url\": string\n }]\n}",
          "expected_output": {
            "favicons": [
              {
                "size": "180x180",
                "url": "/apple-touch-icon.png"
              },
              {
                "size": "32x32",
                "url": "/favicon-32x32.png"
              },
              {
                "size": "16x16",
                "url": "/favicon-16x16.png"
              }
            ]
          },
          "tags": [
            "METADATA_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "6.json"
        },
        "model_output": {
          "favicons": [
            {
              "size": "180x180",
              "url": "/apple-touch-icon.png"
            },
            {
              "size": "32x32",
              "url": "/favicon-32x32.png"
            },
            {
              "size": "16x16",
              "url": "/favicon-16x16.png"
            }
          ]
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "7.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0000000715255737,
        "cost": 0.00091,
        "usage": {
          "input_tokens": 248.0,
          "output_tokens": 29.0,
          "total_tokens": 277.0
        },
        "latency": 1.0724952220916748,
        "test_case": {
          "expected_output": {
            "title": "Example Domain",
            "num_links": 1,
            "num_paragraphs": 2
          },
          "input": {
            "input_file": "example.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into JSON: \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"title\": \"string\",\n  \"num_links\": \"number\",\n  \"num_paragraphs\": \"number\"\n}",
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "7.json"
        },
        "model_output": {
          "title": "Example Domain",
          "num_links": 1,
          "num_paragraphs": 2
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "1.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999642372132,
        "cost": 0.1175775,
        "usage": {
          "input_tokens": 46899.0,
          "output_tokens": 33.0,
          "total_tokens": 46932.0
        },
        "latency": 9.382360935211182,
        "test_case": {
          "expected_output": {
            "insights": {
              "total_pageviews": 584,
              "total_visitors": 417
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic pageview metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following metrics into a JSON object:\n- Total pageviews\n- Total visitors\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"total_pageviews\": number,\n    \"total_visitors\": number\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "total_pageviews": 584,
            "total_visitors": 417
          }
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "2.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.1178475,
        "usage": {
          "input_tokens": 46915.0,
          "output_tokens": 56.0,
          "total_tokens": 46971.0
        },
        "latency": 11.010074138641357,
        "test_case": {
          "expected_output": {
            "insights": {
              "referral_sources": {
                "direct": 240,
                "twitter.com": 68,
                "news.ycombinator.com": 41
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the top 3 referral sources from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the top 3 referral sources with their pageview counts into JSON.\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"referral_sources\": {\n      \"direct\": number,\n      \"twitter.com\": number,\n      \"news.ycombinator.com\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "referral_sources": {
              "direct": 240,
              "twitter.com": 68,
              "news.ycombinator.com": 41
            }
          }
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "3.json",
        "difficulty": "easy",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9999999284744263,
        "cost": 0.11767999999999999,
        "usage": {
          "input_tokens": 46900.0,
          "output_tokens": 43.0,
          "total_tokens": 46943.0
        },
        "latency": 9.157687902450562,
        "test_case": {
          "expected_output": {
            "insights": {
              "device_usage": {
                "mobile": 68,
                "desktop": 32,
                "tablet": 0.7
              }
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract device usage percentages from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract the percentage breakdown of device types used into JSON.\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"device_usage\": {\n      \"mobile\": number,\n      \"desktop\": number,\n      \"tablet\": number\n    }\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "3.json"
        },
        "model_output": {
          "insights": {
            "device_usage": {
              "mobile": 68,
              "desktop": 32,
              "tablet": 0.7
            }
          }
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "4.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.267125,
        "usage": {
          "input_tokens": 106622.0,
          "output_tokens": 57.0,
          "total_tokens": 106679.0
        },
        "latency": 30.194819927215576,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract basic post information from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML content and extract the following basic post information into a JSON object. \n- Post title\n- Author name\n- Subreddit name\n- Post score\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"post_title\": string,\n \"author\": string,\n \"subreddit\": string,\n \"post_score\": string\n}",
          "expected_output": {
            "post_title": "Is there a simple way to monitor Bedrock Costs?",
            "author": "Bob321423",
            "subreddit": "r/aws",
            "post_score": "5"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "4.json"
        },
        "model_output": {
          "post_title": "Is there a simple way to monitor Bedrock Costs?",
          "author": "Bob321423",
          "subreddit": "r/aws",
          "post_score": 5
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "5.json",
        "difficulty": "easy",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 1.0000000715255737,
        "cost": 0.26723749999999996,
        "usage": {
          "input_tokens": 106635.0,
          "output_tokens": 65.0,
          "total_tokens": 106700.0
        },
        "latency": 30.90306305885315,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"community_name\": string,\n \"total_members\": number,\n \"active_members\": number,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "r/aws",
            "total_members": 316355,
            "active_members": 48,
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "easy",
          "test_id": "5.json"
        },
        "model_output": {
          "community_name": "r/aws",
          "total_members": 316355,
          "active_members": 48,
          "created_date": "Jan 26, 2008",
          "community_type": "public"
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "1.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9777532935142517,
        "cost": 0.1180925,
        "usage": {
          "input_tokens": 46957.0,
          "output_tokens": 70.0,
          "total_tokens": 47027.0
        },
        "latency": 12.24924612045288,
        "test_case": {
          "expected_output": {
            "insights": {
              "top_page": {
                "url": "/blog/tone-evaluation",
                "pageviews": 296,
                "percentage_of_total": 50.5,
                "has_social_traffic": true
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze the most popular page's metrics from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract information about the most visited page into JSON:\n- The page URL\n- Number of pageviews\n- Calculate what percentage of total pageviews this represents\n- Whether it received any social media traffic (from Twitter, Facebook, or LinkedIn)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"top_page\": {\n      \"url\": string,\n      \"pageviews\": number,\n      \"percentage_of_total\": number,\n      \"has_social_traffic\": boolean\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "top_page": {
              "url": "/blog/tone-evaluation",
              "pageviews": 296,
              "percentage_of_total": 50.685,
              "has_social_traffic": true
            }
          }
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "2.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9776516556739807,
        "cost": 0.1180775,
        "usage": {
          "input_tokens": 46943.0,
          "output_tokens": 72.0,
          "total_tokens": 47015.0
        },
        "latency": 12.542404890060425,
        "test_case": {
          "expected_output": {
            "insights": {
              "mobile_stats": {
                "percentage": 68,
                "dominant_browser": "iOS Safari",
                "browser_share": 48,
                "alignment_score": 0.71
              }
            }
          },
          "tags": [
            "ANALYTICS_EXTRACTION"
          ],
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Analyze mobile usage patterns from the provided webpage HTML.",
          "user_prompt": "Please analyze the webpage HTML content and extract mobile usage patterns into JSON:\n- Mobile device usage percentage\n- Most used mobile browser\n- That browser's overall share percentage\n- Calculate an alignment score (browser_share/mobile_percentage)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"mobile_stats\": {\n      \"percentage\": number,\n      \"dominant_browser\": string,\n      \"browser_share\": number,\n      \"alignment_score\": number\n    }\n  }\n}",
          "difficulty": "medium",
          "test_id": "2.json"
        },
        "model_output": {
          "insights": {
            "mobile_stats": {
              "percentage": 68,
              "dominant_browser": "iOS Safari",
              "browser_share": 48,
              "alignment_score": 0.7058823529411765
            }
          }
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "3.json",
        "difficulty": "medium",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "SEMANTIC_EXTRACTION"
        ],
        "score": 0.9907679438591004,
        "cost": 0.2675975,
        "usage": {
          "input_tokens": 106627.0,
          "output_tokens": 103.0,
          "total_tokens": 106730.0
        },
        "latency": 37.30245399475098,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "tags": [
            "ANALYTICS_EXTRACTION",
            "SEMANTIC_EXTRACTION"
          ],
          "system_prompt": "You are a data extraction assistant. Analyze comment patterns and extract comment-related metrics from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following comment information into JSON:\n- Total number of comments\n- List of all comment authors\n- Timeline of comments (how long ago each was posted)\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"total_comments\": number,\n \"comment_authors\": string[],\n \"comments_timeline\": string[]\n}",
          "expected_output": {
            "total_comments": 5,
            "comment_authors": [
              "Truelikegiroux",
              "TechMktr",
              "MrPebblesMeow",
              "AdRepulsive7837",
              "noydoc"
            ],
            "comments_timeline": [
              "5 months ago",
              "5 months ago",
              "4 months ago",
              "4 months ago",
              "2 months ago"
            ]
          },
          "difficulty": "medium",
          "test_id": "3.json"
        },
        "model_output": {
          "total_comments": 5,
          "comment_authors": [
            "Bob321423",
            "Truelikegiroux",
            "TechMktr",
            "MrPebblesMeow",
            "noydoc"
          ],
          "comments_timeline": [
            "5 months ago",
            "5 months ago",
            "4 months ago",
            "2 months ago",
            "2 months ago"
          ]
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "4.json",
        "difficulty": "medium",
        "tags": [
          "METADATA_EXTRACTION",
          "ANALYTICS_EXTRACTION"
        ],
        "score": 0.9849911093711853,
        "cost": 0.26723749999999996,
        "usage": {
          "input_tokens": 106635.0,
          "output_tokens": 65.0,
          "total_tokens": 106700.0
        },
        "latency": 31.41116189956665,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract community statistics and metadata from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following community information into JSON:\n- Community name\n- Total member count\n- Currently active members\n- Community creation date\n- Community type\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"community_name\": string,\n \"total_members\": string,\n \"active_members\": string,\n \"created_date\": string,\n \"community_type\": string\n}",
          "expected_output": {
            "community_name": "aws",
            "total_members": "316355",
            "active_members": "48",
            "created_date": "Jan 26, 2008",
            "community_type": "Public"
          },
          "tags": [
            "METADATA_EXTRACTION",
            "ANALYTICS_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "4.json"
        },
        "model_output": {
          "community_name": "r/aws",
          "total_members": "316355",
          "active_members": "48",
          "created_date": "Jan 26, 2008",
          "community_type": "public"
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "5.json",
        "difficulty": "medium",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "MEDIA_EXTRACTION"
        ],
        "error": "No valid JSON found in response",
        "score": 0.0,
        "cost": 0.0,
        "usage": {
          "input_tokens": 0,
          "output_tokens": 0
        },
        "latency": 20.708315134048462,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract the main logo SVG content and properties from the provided webpage HTML.",
          "user_prompt": "Please extract the main navigation logo SVG element, including its viewBox, dimensions, and path data. Don't deconstruct the paths. Store them as strings wtih the tag inside. \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"logo\": {\n   \"viewBox\": string,\n   \"width\": string,\n   \"height\": string,\n   \"paths\": string[]\n }\n}",
          "expected_output": {
            "logo": {
              "viewBox": "0 0 100 100",
              "width": "30px",
              "height": "30px",
              "paths": [
                "<rect height=\"30\" width=\"10\" x=\"20\" y=\"53\"></rect>",
                "<rect height=\"48\" width=\"10\" x=\"44\" y=\"35\"></rect>",
                "<rect height=\"65\" width=\"10\" x=\"68\" y=\"18\"></rect>"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "medium",
          "test_id": "5.json"
        },
        "model_output": null
      },
      {
        "model": "command-r-plus",
        "test_id": "1.json",
        "difficulty": "hard",
        "tags": [
          "ANALYTICS_EXTRACTION",
          "METADATA_EXTRACTION",
          "STRUCTURAL_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.11816,
        "usage": {
          "input_tokens": 46956.0,
          "output_tokens": 77.0,
          "total_tokens": 47033.0
        },
        "latency": 12.695034980773926,
        "test_case": {
          "expected_output": {
            "insights": {
              "most_popular_page": "/blog/tone-evaluation",
              "most_popular_referral_source": "twitter.com",
              "dominant_device_type": "Mobile",
              "dominant_browser": "iOS Safari",
              "dominant_country": "United States"
            }
          },
          "input": {
            "input_file": "analytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract key analytics insights from the provided webpage HTML and format them according to the specified schema.",
          "user_prompt": "Please analyze the webpage HTML content and extract the following analytics insights into a JSON object:\n- Most visited page\n- Top referral source\n- Most common device type\n- Most used browser\n- Country with highest traffic\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n  \"insights\": {\n    \"most_popular_page\": string,\n    \"most_popular_referral_source\": string,\n    \"dominant_device_type\": string,\n    \"dominant_browser\": string,\n    \"dominant_country\": string\n  }\n}",
          "tags": [
            "ANALYTICS_EXTRACTION",
            "METADATA_EXTRACTION",
            "STRUCTURAL_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "1.json"
        },
        "model_output": {
          "insights": {
            "most_popular_page": "/blog/tone-evaluation",
            "most_popular_referral_source": "twitter.com",
            "dominant_device_type": "Mobile",
            "dominant_browser": "iOS Safari",
            "dominant_country": "United States"
          }
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "2.json",
        "difficulty": "hard",
        "tags": [
          "STRUCTURAL_EXTRACTION",
          "METADATA_EXTRACTION"
        ],
        "score": 0.7189281940460206,
        "cost": 0.273195,
        "usage": {
          "input_tokens": 106658.0,
          "output_tokens": 655.0,
          "total_tokens": 107313.0
        },
        "latency": 109.01054120063782,
        "test_case": {
          "input": {
            "input_file": "reddit.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and organize the complete navigation structure and resource links from the provided Reddit webpage HTML.",
          "user_prompt": "Please analyze the Reddit webpage HTML and extract the following navigation structure into JSON:\n- Main resource links with their titles and URLs\n- Policy links with their titles and URLs\n- All sidebar resource links\n\nOrganize the information hierarchically\n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"resources\": {\n   \"main_links\": [{ \"title\": string, \"url\": string }],\n   \"policies\": [{ \"title\": string, \"url\": string }],\n   \"sidebar_resources\": string[]\n }\n}",
          "expected_output": {
            "resources": {
              "main_links": [
                {
                  "title": "About Reddit",
                  "url": "https://www.redditinc.com"
                },
                {
                  "title": "Advertise",
                  "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
                },
                {
                  "title": "Help",
                  "url": "https://support.reddithelp.com/hc?utm_source=reddit&utm_medium=footer&utm_campaign=evergreen"
                },
                {
                  "title": "Blog",
                  "url": "https://redditblog.com/"
                },
                {
                  "title": "Careers",
                  "url": "https://www.redditinc.com/careers"
                },
                {
                  "title": "Press",
                  "url": "https://www.redditinc.com/press"
                }
              ],
              "policies": [
                {
                  "title": "Content Policy",
                  "url": "https://www.redditinc.com/policies/content-policy"
                },
                {
                  "title": "Privacy Policy",
                  "url": "https://www.reddit.com/policies/privacy-policy"
                },
                {
                  "title": "User Agreement",
                  "url": "https://www.redditinc.com/policies/user-agreement"
                }
              ],
              "sidebar_resources": [
                "Amazon Web Services blog",
                "AWS status page",
                "AWS documentation",
                "AWS YouTube channel",
                "AWS Samples on GitHub",
                "AWS Labs on GitHub",
                "AWS General Reference",
                "High Scalability",
                "re:Invent Videos",
                "Workshops",
                "AWS Geek: Cloud Diagrams",
                "AWS Stash",
                "AWS Architecture Center",
                "AWS re:Post"
              ]
            }
          },
          "tags": [
            "STRUCTURAL_EXTRACTION",
            "METADATA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "2.json"
        },
        "model_output": {
          "resources": {
            "main_links": [
              {
                "title": "Home",
                "url": "https://www.reddit.com/"
              },
              {
                "title": "About",
                "url": "https://www.redditinc.com/"
              },
              {
                "title": "User Agreement",
                "url": "https://www.redditinc.com/policies/user-agreement"
              },
              {
                "title": "Privacy Policy",
                "url": "https://www.redditinc.com/policies/privacy-policy"
              },
              {
                "title": "Content Policy",
                "url": "https://www.redditinc.com/policies/content-policy"
              },
              {
                "title": "Press",
                "url": "https://www.redditinc.com/press"
              },
              {
                "title": "Blog",
                "url": "https://redditblog.com/"
              },
              {
                "title": "Careers",
                "url": "https://www.redditinc.com/careers"
              },
              {
                "title": "Communities",
                "url": "https://www.reddit.com/best/communities/1/"
              },
              {
                "title": "Topics",
                "url": "https://www.reddit.com/topics/a-1/"
              },
              {
                "title": "Best of Reddit",
                "url": "https://www.reddit.com/posts/2024/global/"
              },
              {
                "title": "Rules",
                "url": "https://www.reddit.com/rules/"
              },
              {
                "title": "Advertise",
                "url": "https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=left_nav_cta"
              }
            ],
            "policies": [
              {
                "title": "Content Policy",
                "url": "https://www.redditinc.com/policies/content-policy"
              },
              {
                "title": "User Agreement",
                "url": "https://www.redditinc.com/policies/user-agreement"
              },
              {
                "title": "Privacy Policy",
                "url": "https://www.redditinc.com/policies/privacy-policy"
              }
            ],
            "sidebar_resources": [
              {
                "title": "Wiki",
                "url": "/r/aws/wiki/index/"
              },
              {
                "title": "Moderators",
                "url": "/r/aws/about/moderators/"
              },
              {
                "title": "Create a community",
                "url": "https://www.reddit.com/r/aws/wiki/index#wiki_create_a_community"
              },
              {
                "title": "Message the moderators",
                "url": "/message/compose/?to=%2Fr%2Faws"
              }
            ]
          }
        }
      },
      {
        "model": "command-r-plus",
        "test_id": "3.json",
        "difficulty": "hard",
        "tags": [
          "MEDIA_EXTRACTION"
        ],
        "score": 1.0,
        "cost": 0.0310475,
        "usage": {
          "input_tokens": 12391.0,
          "output_tokens": 7.0,
          "total_tokens": 12398.0
        },
        "latency": 1.8426921367645264,
        "test_case": {
          "input": {
            "input_file": "simpleanalytics.html"
          },
          "system_prompt": "You are a data extraction assistant. Extract and decode any base64 encoded logo images from the provided webpage HTML.",
          "user_prompt": "Please analyze the HTML for any base64 encoded logo images. Extract the base64 encoded string or return empty string \n\nReturn only the JSON object, with no additional text, formatted according to this schema:\n{\n \"encodedImage\": string\n}",
          "expected_output": {
            "encodedImage": ""
          },
          "tags": [
            "MEDIA_EXTRACTION"
          ],
          "difficulty": "hard",
          "test_id": "3.json"
        },
        "model_output": {
          "encodedImage": ""
        }
      }
  ]